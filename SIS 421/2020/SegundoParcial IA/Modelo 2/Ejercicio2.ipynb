{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ejercicio2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSAi33jxQxuqKEED/0V7r9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zelechos/IA_Code/blob/master/SegundoParcial%20IA/Ejercicio2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S5JoroD4rXS"
      },
      "source": [
        "# Modelo 2\n",
        "## La referencias usada para realizar este model es\n",
        "[Repsitorio sis421](https://github.com/cwpachecol/SIS421)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zxop9AHk7ssN",
        "outputId": "3b1acc0c-bdfe-4dce-b5dd-cb7f490a80bc"
      },
      "source": [
        "# montamos nuestro drive al proyecto\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LkuPvlJPHUg"
      },
      "source": [
        "# Traemos nuestro dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QrewYU7d-GDM",
        "outputId": "a75e60d5-663a-405c-aea3-376f90176f4a"
      },
      "source": [
        "#hacemos una copia para trabajar con el dataset\n",
        "import shutil\n",
        "\n",
        "shutil.copy(\"/content/drive/MyDrive/revisiones.json\",\"/content/revisiones.json\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/revisiones.json'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IbdumnGPKLA"
      },
      "source": [
        "# Realizamos el Preprocesamiento de Textos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX0cMHQd7plb",
        "outputId": "e014b898-dda3-4a7d-efd2-d473a065ed0b"
      },
      "source": [
        "import json\n",
        "\n",
        "with open('/content/revisiones.json') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "#accedemos a la evaluation\n",
        "print(\"evaluation : \", data[\"paper\"][0][\"review\"][0][\"evaluation\"])\n",
        "\n",
        "#accedemos a la text\n",
        "print(\"text : \", data[\"paper\"][0][\"review\"][0][\"text\"])\n",
        "\n",
        "#averiguando la longitud\n",
        "print(\"longitud : \", len(data[\"paper\"][0][\"review\"]))\n",
        "\n",
        "paper = data[\"paper\"]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "evaluation :  1\n",
            "text :  - El artículo aborda un problema contingente y muy relevante, e incluye tanto un diagnóstico nacional de uso de buenas prácticas como una solución (buenas prácticas concretas). - El lenguaje es adecuado.  - El artículo se siente como la concatenación de tres artículos diferentes: (1) resultados de una encuesta, (2) buenas prácticas de seguridad, (3) incorporación de buenas prácticas. - El orden de las secciones sería mejor si refleja este orden (la versión revisada es #2, #1, #3). - El artículo no tiene validación de ningún tipo, ni siquiera por evaluación de expertos.\n",
            "longitud :  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDzt5coZH9A8",
        "outputId": "ca05d9c0-5d4d-439f-a502-34ae068d998c"
      },
      "source": [
        "# Capturamos todas las reviews en una lista\n",
        "Reviews = []\n",
        "\n",
        "cont = 0\n",
        "for x in paper:\n",
        "  # print(x[cont][\"review\"])\n",
        "  Reviews.append(data[\"paper\"][cont][\"review\"])\n",
        "  cont += 1\n",
        "\n",
        "print(len(Reviews))\n",
        "print(Reviews[171][0][\"text\"])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "172\n",
            "El artículo describe básicamente los componentes de un aerodeslizador, y el sensor que podría ser utilizado para el control de navegación.  Es un estudio más bien teórico que no presenta evidencias de su construcción.  No queda claro si la propuesta ya fue publicada por el inserto en pie de página.  Se deben corregir varios errores de tipo gramatical; Ejemplos: Primer párrafo introducción ”con el término” y no “el término” C. Sistema de propulsión … a los cuales se acoplará Texto figura 2 debe incorporarse al pie de la figura Figura 3 sin título Figura 6 después de la 3? Penúltimo párrafo hoja 4 (“con estés….”) Enumerar ecuaciones.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0VLtW32KDBm"
      },
      "source": [
        "# Tenemos reviews vacias 51,61,105"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvEpf-KUJAsI",
        "outputId": "d933ac04-b795-4482-cad0-f6e0a6b7c8f6"
      },
      "source": [
        "# print(len(Reviews[0]))\n",
        "cont = 1 \n",
        "# Obtenemos todas las longitudes de nuestra Lista de Reviews\n",
        "Longitudes = []\n",
        "for i in Reviews:\n",
        "  # print(cont ,\"---->\",i)\n",
        "  Longitudes.append(len(i))\n",
        "  cont += 1\n",
        "\n",
        "print(Longitudes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 3, 3, 2, 3, 3, 2, 3, 2, 2, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 2, 3, 3, 3, 3, 3, 2, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 3, 1, 2, 4, 0, 1, 3, 1, 4, 2, 3, 1, 2, 1, 0, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 3, 2, 2, 3, 1, 1, 2, 4, 2, 1, 1, 1, 3, 2, 2, 2, 2, 2, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 0, 3, 3, 3, 3, 3, 3, 4, 3, 3, 2, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meQBeIkFK8pR",
        "outputId": "ce845364-171e-4931-b08e-3fc726358131"
      },
      "source": [
        "Evalutions = []\n",
        "Texts = []\n",
        "\n",
        "Data = []\n",
        "for index in range(len(Longitudes)):\n",
        "  # print(index)\n",
        "  for i in range(Longitudes[index]):\n",
        "    Data.append([ Reviews[index][i][\"evaluation\"] , Reviews[index][i][\"text\"]])\n",
        "    # Evalutions.append(Reviews[index][i][\"evaluation\"])\n",
        "    # Texts.append(Reviews[index][i][\"text\"])\n",
        "\n",
        "print(Data[404])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1', 'El artículo describe básicamente los componentes de un aerodeslizador, y el sensor que podría ser utilizado para el control de navegación.  Es un estudio más bien teórico que no presenta evidencias de su construcción.  No queda claro si la propuesta ya fue publicada por el inserto en pie de página.  Se deben corregir varios errores de tipo gramatical; Ejemplos: Primer párrafo introducción ”con el término” y no “el término” C. Sistema de propulsión … a los cuales se acoplará Texto figura 2 debe incorporarse al pie de la figura Figura 3 sin título Figura 6 después de la 3? Penúltimo párrafo hoja 4 (“con estés….”) Enumerar ecuaciones.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIOdVY5tPsiW"
      },
      "source": [
        "# Contamos con 405 Textos para entrenar nuestro modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMz8Sx0QPrxO",
        "outputId": "0afe7e3a-d570-4559-86c0-c66f400dd15b"
      },
      "source": [
        "print(len(Data))\n",
        "\n",
        "cont = 1 \n",
        "\n",
        "\n",
        "for i in Data:\n",
        "    # print(cont,\"--> \",i[0])\n",
        "    if i[0] == '-2':\n",
        "      i[0] = -2\n",
        "    elif i[0] == '-1':\n",
        "      i[0] = -1\n",
        "    elif i[0] == '0':\n",
        "      i[0] = 0\n",
        "    elif i[0] == '1':\n",
        "      i[0] = 1\n",
        "    elif i[0] == '2':\n",
        "      i[0] = 2\n",
        "\n",
        "    cont += 1\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZu37hzp7n5q"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "Train = []\n",
        "Test = []\n",
        "v =[]\n",
        "t =[]\n",
        "for i in Data:\n",
        "    v.append(i[0])\n",
        "    t.append(i[1])\n",
        "\n",
        "\n",
        "data = {'Valoracion': v[:300],\n",
        "        'Texto': t[:300]}\n",
        "\n",
        "data1 = {'Valoracion': v[300:],\n",
        "        'Texto': t[300:]}\n",
        "\n",
        "os.mkdir('/content/Dataset')\n",
        "df = pd.DataFrame(data, columns = ['Valoracion', 'Texto'])\n",
        "df1 = pd.DataFrame(data1, columns = ['Valoracion', 'Texto'])\n",
        "df.to_csv('/content/Dataset/train.csv')\n",
        "df1.to_csv('/content/Dataset/test.csv')\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF78Uv5VPjKF",
        "outputId": "c9dd83f8-6035-4576-bcbf-c761b427f7f3"
      },
      "source": [
        "print(len(v[:300]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdb4i0jL7spw",
        "outputId": "e15764f9-ba97-46f9-ebb4-91ef0b2a4ed6"
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import spacy\n",
        "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuKQl-jb7snF"
      },
      "source": [
        "#python -m spacy download en\n",
        "spacy_en = spacy.load(\"en\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRiFWF937sfl"
      },
      "source": [
        "def tokenize(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtC0Tju83wBo"
      },
      "source": [
        "Texto = Field(sequential=True, use_vocab=True, tokenize=tokenize, lower=True)\n",
        "Valoracion = Field(sequential=False, use_vocab=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ulh7zIkt38tG"
      },
      "source": [
        "fields = {\"Texto\": (\"t\", Texto), \"Valoracion\": (\"v\", Valoracion)}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnwxD-za5pi_"
      },
      "source": [
        "train_data, test_data = TabularDataset.splits(\n",
        "                                        path='/content/Dataset',\n",
        "                                        train='train.csv',\n",
        "                                        test='test.csv',\n",
        "                                        format='csv',\n",
        "                                        fields=fields)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwzALLayVSW6",
        "outputId": "9da777f7-e053-452d-d6b4-a6df4f7604c0"
      },
      "source": [
        "len(train_data) , len(test_data)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 105)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBtZ6YmVVagh",
        "outputId": "98931ddd-cfb7-48ea-896b-9bb957b8d663"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'t': ['-', 'el', 'artículo', 'aborda', 'un', 'problema', 'contingente', 'y', 'muy', 'relevante', ',', 'e', 'incluye', 'tanto', 'un', 'diagnóstico', 'nacional', 'de', 'uso', 'de', 'buenas', 'prácticas', 'como', 'una', 'solución', '(', 'buenas', 'prácticas', 'concretas', ')', '.', '-', 'el', 'lenguaje', 'es', 'adecuado', '.', ' ', '-', 'el', 'artículo', 'se', 'siente', 'como', 'la', 'concatenación', 'de', 'tres', 'artículos', 'diferentes', ':', '(', '1', ')', 'resultados', 'de', 'una', 'encuesta', ',', '(', '2', ')', 'buenas', 'prácticas', 'de', 'seguridad', ',', '(', '3', ')', 'incorporación', 'de', 'buenas', 'prácticas', '.', '-', 'el', 'orden', 'de', 'las', 'secciones', 'sería', 'mejor', 'si', 'refleja', 'este', 'orden', '(', 'la', 'versión', 'revisada', 'es', '#', '2', ',', '#', '1', ',', '#', '3', ')', '.', '-', 'el', 'artículo', 'no', 'tiene', 'validación', 'de', 'ningún', 'tipo', ',', 'ni', 'siquiera', 'por', 'evaluación', 'de', 'expertos', '.'], 'v': '1'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUbTP7q75peH",
        "outputId": "5d4a253d-c539-4567-b88b-f92431ffd978",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Texto.build_vocab(train_data, max_size=10000, min_freq=1,vectors=\"glove.6B.100d\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:43, 5.26MB/s]                           \n",
            "100%|█████████▉| 399829/400000 [00:21<00:00, 18556.33it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqdd7e9eh8jY",
        "outputId": "a97fe8c5-cf2e-46b9-91d4-55eaa0745196"
      },
      "source": [
        "Texto.vocab.freqs.most_common(25)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('de', 3071),\n",
              " ('.', 2116),\n",
              " (',', 2043),\n",
              " ('la', 1580),\n",
              " ('el', 1446),\n",
              " ('en', 1349),\n",
              " ('que', 1022),\n",
              " (' ', 953),\n",
              " ('y', 943),\n",
              " ('se', 876),\n",
              " ('no', 708),\n",
              " ('un', 669),\n",
              " ('es', 630),\n",
              " ('a', 629),\n",
              " ('los', 586),\n",
              " ('una', 565),\n",
              " ('del', 544),\n",
              " ('\"', 512),\n",
              " ('las', 488),\n",
              " ('para', 478),\n",
              " ('-', 391),\n",
              " (')', 358),\n",
              " ('por', 353),\n",
              " ('artículo', 331),\n",
              " ('con', 326)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LIoJO48iDBP",
        "outputId": "5a9d6b77-0b55-4ca5-9ac9-c096fb555dd2"
      },
      "source": [
        "Texto.vocab.itos[:10]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', 'de', '.', ',', 'la', 'el', 'en', 'que', ' ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjDmKD5AWL0G"
      },
      "source": [
        "train_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, test_data), batch_size=2, device=device\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6UKhlEB5pcJ"
      },
      "source": [
        "class RNN_LSTM(nn.Module):\n",
        "    def __init__(self, input_size, embed_size, hidden_size, num_layers):\n",
        "        super(RNN_LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embed_size)\n",
        "        self.rnn = nn.LSTM(embed_size, hidden_size, num_layers)\n",
        "        self.fc_out = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Set initial hidden and cell states\n",
        "        h0 = torch.zeros(self.num_layers, x.size(1), self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(1), self.hidden_size).to(device)\n",
        "\n",
        "        embedded = self.embedding(x)\n",
        "        outputs, _ = self.rnn(embedded, (h0, c0))\n",
        "        prediction = self.fc_out(outputs[-1, :, :])\n",
        "\n",
        "        return prediction"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUppRqm65pZo"
      },
      "source": [
        "# Hyperparameters\n",
        "input_size = len(Texto.vocab)\n",
        "hidden_size = 512\n",
        "num_layers = 2\n",
        "embedding_size = 100\n",
        "learning_rate = 0.005\n",
        "num_epochs = 10\n",
        "\n",
        "# Initialize network\n",
        "model = RNN_LSTM(input_size, embedding_size, hidden_size, num_layers).to(device)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5bJUvKNReQh"
      },
      "source": [
        "# (NOT COVERED IN YOUTUBE VIDEO): Load the pretrained embeddings onto our model\n",
        "pretrained_embeddings = Texto.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juqGZBHyuYjW"
      },
      "source": [
        "# Entrenamos la Red Neuronal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHd33sDwReOZ",
        "outputId": "88787e41-7a13-4cde-da7b-e53cc98ebcc0"
      },
      "source": [
        "# Train Network\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    for batch_idx, batch in enumerate(train_iterator):\n",
        "        # Get data to cuda if possible\n",
        "        data = batch.t.to(device=device)\n",
        "        targets = batch.v.to(device=device)\n",
        "\n",
        "        # forward\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores.squeeze(1), targets.type_as(scores))\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent\n",
        "        optimizer.step()\n",
        "\n",
        "        \n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} loss {loss:.5f} val_loss {loss:.5f} \")\n",
        "print(scores)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10 loss 0.68975 val_loss 0.68975 \n",
            "Epoch 1/10 loss 1.14866 val_loss 1.14866 \n",
            "Epoch 1/10 loss 0.71695 val_loss 0.71695 \n",
            "Epoch 1/10 loss 0.64632 val_loss 0.64632 \n",
            "Epoch 1/10 loss 0.89333 val_loss 0.89333 \n",
            "Epoch 1/10 loss 0.11160 val_loss 0.11160 \n",
            "Epoch 1/10 loss 0.59914 val_loss 0.59914 \n",
            "Epoch 1/10 loss 1.71504 val_loss 1.71504 \n",
            "Epoch 1/10 loss 1.74193 val_loss 1.74193 \n",
            "Epoch 1/10 loss 0.91659 val_loss 0.91659 \n",
            "Epoch 1/10 loss 2.02440 val_loss 2.02440 \n",
            "Epoch 1/10 loss 0.95791 val_loss 0.95791 \n",
            "Epoch 1/10 loss 0.15115 val_loss 0.15115 \n",
            "Epoch 1/10 loss 0.51371 val_loss 0.51371 \n",
            "Epoch 1/10 loss 1.52612 val_loss 1.52612 \n",
            "Epoch 1/10 loss 0.49871 val_loss 0.49871 \n",
            "Epoch 1/10 loss 0.43452 val_loss 0.43452 \n",
            "Epoch 1/10 loss 0.72487 val_loss 0.72487 \n",
            "Epoch 1/10 loss 1.40831 val_loss 1.40831 \n",
            "Epoch 1/10 loss 0.91573 val_loss 0.91573 \n",
            "Epoch 1/10 loss 0.89564 val_loss 0.89564 \n",
            "Epoch 1/10 loss 1.58765 val_loss 1.58765 \n",
            "Epoch 1/10 loss 1.71649 val_loss 1.71649 \n",
            "Epoch 1/10 loss 1.19549 val_loss 1.19549 \n",
            "Epoch 1/10 loss 0.73265 val_loss 0.73265 \n",
            "Epoch 1/10 loss 1.26192 val_loss 1.26192 \n",
            "Epoch 1/10 loss 1.53748 val_loss 1.53748 \n",
            "Epoch 1/10 loss 0.80782 val_loss 0.80782 \n",
            "Epoch 1/10 loss 0.81794 val_loss 0.81794 \n",
            "Epoch 1/10 loss 0.93559 val_loss 0.93559 \n",
            "Epoch 1/10 loss 0.06525 val_loss 0.06525 \n",
            "Epoch 1/10 loss -0.14751 val_loss -0.14751 \n",
            "Epoch 1/10 loss 2.05672 val_loss 2.05672 \n",
            "Epoch 1/10 loss -2.84515 val_loss -2.84515 \n",
            "Epoch 1/10 loss -2.04192 val_loss -2.04192 \n",
            "Epoch 1/10 loss -1.36197 val_loss -1.36197 \n",
            "Epoch 1/10 loss -6.55325 val_loss -6.55325 \n",
            "Epoch 1/10 loss -2.11322 val_loss -2.11322 \n",
            "Epoch 1/10 loss 7.61833 val_loss 7.61833 \n",
            "Epoch 1/10 loss 0.06966 val_loss 0.06966 \n",
            "Epoch 1/10 loss 6.00321 val_loss 6.00321 \n",
            "Epoch 1/10 loss 3.07202 val_loss 3.07202 \n",
            "Epoch 1/10 loss 6.29254 val_loss 6.29254 \n",
            "Epoch 1/10 loss -6.17188 val_loss -6.17188 \n",
            "Epoch 1/10 loss 6.34128 val_loss 6.34128 \n",
            "Epoch 1/10 loss 9.16107 val_loss 9.16107 \n",
            "Epoch 1/10 loss -5.57712 val_loss -5.57712 \n",
            "Epoch 1/10 loss 0.05686 val_loss 0.05686 \n",
            "Epoch 1/10 loss -0.00749 val_loss -0.00749 \n",
            "Epoch 1/10 loss 0.01479 val_loss 0.01479 \n",
            "Epoch 1/10 loss -10.74600 val_loss -10.74600 \n",
            "Epoch 1/10 loss -8.57268 val_loss -8.57268 \n",
            "Epoch 1/10 loss 9.17026 val_loss 9.17026 \n",
            "Epoch 1/10 loss 12.73160 val_loss 12.73160 \n",
            "Epoch 1/10 loss -3.10585 val_loss -3.10585 \n",
            "Epoch 1/10 loss -12.37247 val_loss -12.37247 \n",
            "Epoch 1/10 loss -12.85310 val_loss -12.85310 \n",
            "Epoch 1/10 loss -6.93517 val_loss -6.93517 \n",
            "Epoch 1/10 loss -15.06852 val_loss -15.06852 \n",
            "Epoch 1/10 loss -0.00413 val_loss -0.00413 \n",
            "Epoch 1/10 loss -4.54066 val_loss -4.54066 \n",
            "Epoch 1/10 loss 19.41429 val_loss 19.41429 \n",
            "Epoch 1/10 loss 5.08172 val_loss 5.08172 \n",
            "Epoch 1/10 loss 5.23211 val_loss 5.23211 \n",
            "Epoch 1/10 loss -10.61533 val_loss -10.61533 \n",
            "Epoch 1/10 loss -0.17315 val_loss -0.17315 \n",
            "Epoch 1/10 loss 16.62455 val_loss 16.62455 \n",
            "Epoch 1/10 loss -11.18433 val_loss -11.18433 \n",
            "Epoch 1/10 loss 5.67689 val_loss 5.67689 \n",
            "Epoch 1/10 loss -5.71351 val_loss -5.71351 \n",
            "Epoch 1/10 loss 17.25516 val_loss 17.25516 \n",
            "Epoch 1/10 loss -17.16417 val_loss -17.16417 \n",
            "Epoch 1/10 loss -23.16862 val_loss -23.16862 \n",
            "Epoch 1/10 loss 11.72762 val_loss 11.72762 \n",
            "Epoch 1/10 loss -12.21344 val_loss -12.21344 \n",
            "Epoch 1/10 loss -6.28807 val_loss -6.28807 \n",
            "Epoch 1/10 loss 25.83301 val_loss 25.83301 \n",
            "Epoch 1/10 loss 6.43930 val_loss 6.43930 \n",
            "Epoch 1/10 loss -0.00108 val_loss -0.00108 \n",
            "Epoch 1/10 loss 12.32831 val_loss 12.32831 \n",
            "Epoch 1/10 loss -6.24866 val_loss -6.24866 \n",
            "Epoch 1/10 loss 12.56184 val_loss 12.56184 \n",
            "Epoch 1/10 loss 12.21884 val_loss 12.21884 \n",
            "Epoch 1/10 loss 5.85253 val_loss 5.85253 \n",
            "Epoch 1/10 loss 5.65934 val_loss 5.65934 \n",
            "Epoch 1/10 loss -0.05939 val_loss -0.05939 \n",
            "Epoch 1/10 loss 15.55802 val_loss 15.55802 \n",
            "Epoch 1/10 loss 9.84076 val_loss 9.84076 \n",
            "Epoch 1/10 loss -9.20820 val_loss -9.20820 \n",
            "Epoch 1/10 loss 4.37284 val_loss 4.37284 \n",
            "Epoch 1/10 loss 8.26538 val_loss 8.26538 \n",
            "Epoch 1/10 loss 3.81533 val_loss 3.81533 \n",
            "Epoch 1/10 loss -0.08467 val_loss -0.08467 \n",
            "Epoch 1/10 loss -0.01339 val_loss -0.01339 \n",
            "Epoch 1/10 loss -0.02809 val_loss -0.02809 \n",
            "Epoch 1/10 loss 8.44305 val_loss 8.44305 \n",
            "Epoch 1/10 loss 0.18905 val_loss 0.18905 \n",
            "Epoch 1/10 loss -2.20584 val_loss -2.20584 \n",
            "Epoch 1/10 loss 6.17844 val_loss 6.17844 \n",
            "Epoch 1/10 loss 5.39524 val_loss 5.39524 \n",
            "Epoch 1/10 loss 1.48576 val_loss 1.48576 \n",
            "Epoch 1/10 loss 3.31266 val_loss 3.31266 \n",
            "Epoch 1/10 loss 0.89328 val_loss 0.89328 \n",
            "Epoch 1/10 loss 0.16425 val_loss 0.16425 \n",
            "Epoch 1/10 loss 0.68463 val_loss 0.68463 \n",
            "Epoch 1/10 loss 0.92140 val_loss 0.92140 \n",
            "Epoch 1/10 loss 0.39649 val_loss 0.39649 \n",
            "Epoch 1/10 loss -0.22010 val_loss -0.22010 \n",
            "Epoch 1/10 loss 2.35022 val_loss 2.35022 \n",
            "Epoch 1/10 loss 2.57043 val_loss 2.57043 \n",
            "Epoch 1/10 loss 1.75227 val_loss 1.75227 \n",
            "Epoch 1/10 loss 1.60018 val_loss 1.60018 \n",
            "Epoch 1/10 loss 3.67938 val_loss 3.67938 \n",
            "Epoch 1/10 loss 1.02490 val_loss 1.02490 \n",
            "Epoch 1/10 loss 0.71112 val_loss 0.71112 \n",
            "Epoch 1/10 loss -0.17940 val_loss -0.17940 \n",
            "Epoch 1/10 loss 0.30389 val_loss 0.30389 \n",
            "Epoch 1/10 loss 3.37319 val_loss 3.37319 \n",
            "Epoch 1/10 loss -0.79308 val_loss -0.79308 \n",
            "Epoch 1/10 loss 3.42335 val_loss 3.42335 \n",
            "Epoch 1/10 loss -1.05374 val_loss -1.05374 \n",
            "Epoch 1/10 loss 3.79131 val_loss 3.79131 \n",
            "Epoch 1/10 loss -1.13567 val_loss -1.13567 \n",
            "Epoch 1/10 loss 0.09627 val_loss 0.09627 \n",
            "Epoch 1/10 loss 0.06565 val_loss 0.06565 \n",
            "Epoch 1/10 loss -2.55482 val_loss -2.55482 \n",
            "Epoch 1/10 loss 4.26841 val_loss 4.26841 \n",
            "Epoch 1/10 loss 2.87314 val_loss 2.87314 \n",
            "Epoch 1/10 loss 0.05597 val_loss 0.05597 \n",
            "Epoch 1/10 loss 0.03231 val_loss 0.03231 \n",
            "Epoch 1/10 loss 1.32682 val_loss 1.32682 \n",
            "Epoch 1/10 loss -2.25331 val_loss -2.25331 \n",
            "Epoch 1/10 loss 0.08334 val_loss 0.08334 \n",
            "Epoch 1/10 loss -2.31876 val_loss -2.31876 \n",
            "Epoch 1/10 loss 0.07144 val_loss 0.07144 \n",
            "Epoch 1/10 loss 1.41506 val_loss 1.41506 \n",
            "Epoch 1/10 loss 4.14858 val_loss 4.14858 \n",
            "Epoch 1/10 loss 2.74805 val_loss 2.74805 \n",
            "Epoch 1/10 loss 1.31156 val_loss 1.31156 \n",
            "Epoch 1/10 loss -4.24903 val_loss -4.24903 \n",
            "Epoch 1/10 loss 3.40959 val_loss 3.40959 \n",
            "Epoch 1/10 loss 3.24599 val_loss 3.24599 \n",
            "Epoch 1/10 loss 2.83639 val_loss 2.83639 \n",
            "Epoch 1/10 loss -0.45463 val_loss -0.45463 \n",
            "Epoch 1/10 loss -0.69915 val_loss -0.69915 \n",
            "Epoch 1/10 loss 0.78098 val_loss 0.78098 \n",
            "Epoch 1/10 loss 1.16772 val_loss 1.16772 \n",
            "Epoch 1/10 loss 1.24721 val_loss 1.24721 \n",
            "Epoch 1/10 loss 1.03668 val_loss 1.03668 \n",
            "Epoch 1/10 loss 0.34256 val_loss 0.34256 \n",
            "Epoch 2/10 loss -0.60892 val_loss -0.60892 \n",
            "Epoch 2/10 loss 0.18885 val_loss 0.18885 \n",
            "Epoch 2/10 loss 3.47884 val_loss 3.47884 \n",
            "Epoch 2/10 loss -2.63738 val_loss -2.63738 \n",
            "Epoch 2/10 loss 0.04020 val_loss 0.04020 \n",
            "Epoch 2/10 loss -1.83253 val_loss -1.83253 \n",
            "Epoch 2/10 loss 8.32574 val_loss 8.32574 \n",
            "Epoch 2/10 loss -2.17418 val_loss -2.17418 \n",
            "Epoch 2/10 loss 0.01028 val_loss 0.01028 \n",
            "Epoch 2/10 loss 0.00830 val_loss 0.00830 \n",
            "Epoch 2/10 loss 9.93890 val_loss 9.93890 \n",
            "Epoch 2/10 loss 12.24044 val_loss 12.24044 \n",
            "Epoch 2/10 loss 4.48986 val_loss 4.48986 \n",
            "Epoch 2/10 loss -1.99598 val_loss -1.99598 \n",
            "Epoch 2/10 loss -3.61375 val_loss -3.61375 \n",
            "Epoch 2/10 loss 10.37770 val_loss 10.37770 \n",
            "Epoch 2/10 loss 2.96778 val_loss 2.96778 \n",
            "Epoch 2/10 loss 3.67118 val_loss 3.67118 \n",
            "Epoch 2/10 loss 1.00471 val_loss 1.00471 \n",
            "Epoch 2/10 loss 3.27697 val_loss 3.27697 \n",
            "Epoch 2/10 loss 0.85055 val_loss 0.85055 \n",
            "Epoch 2/10 loss -0.93295 val_loss -0.93295 \n",
            "Epoch 2/10 loss 2.03166 val_loss 2.03166 \n",
            "Epoch 2/10 loss 2.74673 val_loss 2.74673 \n",
            "Epoch 2/10 loss 1.69993 val_loss 1.69993 \n",
            "Epoch 2/10 loss 0.02038 val_loss 0.02038 \n",
            "Epoch 2/10 loss 6.48348 val_loss 6.48348 \n",
            "Epoch 2/10 loss -4.51445 val_loss -4.51445 \n",
            "Epoch 2/10 loss 9.75767 val_loss 9.75767 \n",
            "Epoch 2/10 loss 4.96166 val_loss 4.96166 \n",
            "Epoch 2/10 loss -0.00157 val_loss -0.00157 \n",
            "Epoch 2/10 loss 7.18367 val_loss 7.18367 \n",
            "Epoch 2/10 loss -4.54754 val_loss -4.54754 \n",
            "Epoch 2/10 loss 2.28262 val_loss 2.28262 \n",
            "Epoch 2/10 loss -2.18715 val_loss -2.18715 \n",
            "Epoch 2/10 loss -8.76773 val_loss -8.76773 \n",
            "Epoch 2/10 loss 2.27661 val_loss 2.27661 \n",
            "Epoch 2/10 loss -2.32980 val_loss -2.32980 \n",
            "Epoch 2/10 loss -2.39076 val_loss -2.39076 \n",
            "Epoch 2/10 loss -0.00653 val_loss -0.00653 \n",
            "Epoch 2/10 loss -7.78426 val_loss -7.78426 \n",
            "Epoch 2/10 loss 11.03649 val_loss 11.03649 \n",
            "Epoch 2/10 loss -2.78579 val_loss -2.78579 \n",
            "Epoch 2/10 loss 8.54852 val_loss 8.54852 \n",
            "Epoch 2/10 loss 2.82049 val_loss 2.82049 \n",
            "Epoch 2/10 loss 0.01710 val_loss 0.01710 \n",
            "Epoch 2/10 loss 0.00520 val_loss 0.00520 \n",
            "Epoch 2/10 loss -2.65644 val_loss -2.65644 \n",
            "Epoch 2/10 loss -7.98588 val_loss -7.98588 \n",
            "Epoch 2/10 loss 8.13581 val_loss 8.13581 \n",
            "Epoch 2/10 loss 2.72938 val_loss 2.72938 \n",
            "Epoch 2/10 loss 2.72569 val_loss 2.72569 \n",
            "Epoch 2/10 loss 0.00528 val_loss 0.00528 \n",
            "Epoch 2/10 loss 2.56286 val_loss 2.56286 \n",
            "Epoch 2/10 loss -2.46482 val_loss -2.46482 \n",
            "Epoch 2/10 loss 0.00080 val_loss 0.00080 \n",
            "Epoch 2/10 loss 4.80832 val_loss 4.80832 \n",
            "Epoch 2/10 loss 2.31637 val_loss 2.31637 \n",
            "Epoch 2/10 loss -2.19504 val_loss -2.19504 \n",
            "Epoch 2/10 loss -6.37764 val_loss -6.37764 \n",
            "Epoch 2/10 loss 4.30558 val_loss 4.30558 \n",
            "Epoch 2/10 loss 0.01078 val_loss 0.01078 \n",
            "Epoch 2/10 loss 4.19295 val_loss 4.19295 \n",
            "Epoch 2/10 loss 5.97142 val_loss 5.97142 \n",
            "Epoch 2/10 loss -3.69514 val_loss -3.69514 \n",
            "Epoch 2/10 loss -5.30697 val_loss -5.30697 \n",
            "Epoch 2/10 loss 1.80794 val_loss 1.80794 \n",
            "Epoch 2/10 loss 3.54888 val_loss 3.54888 \n",
            "Epoch 2/10 loss 5.10383 val_loss 5.10383 \n",
            "Epoch 2/10 loss 3.11863 val_loss 3.11863 \n",
            "Epoch 2/10 loss 2.77391 val_loss 2.77391 \n",
            "Epoch 2/10 loss 4.70881 val_loss 4.70881 \n",
            "Epoch 2/10 loss -1.60938 val_loss -1.60938 \n",
            "Epoch 2/10 loss -0.45169 val_loss -0.45169 \n",
            "Epoch 2/10 loss 0.29186 val_loss 0.29186 \n",
            "Epoch 2/10 loss -0.92034 val_loss -0.92034 \n",
            "Epoch 2/10 loss 0.35735 val_loss 0.35735 \n",
            "Epoch 2/10 loss 0.34961 val_loss 0.34961 \n",
            "Epoch 2/10 loss 1.26244 val_loss 1.26244 \n",
            "Epoch 2/10 loss 0.79196 val_loss 0.79196 \n",
            "Epoch 2/10 loss -0.43521 val_loss -0.43521 \n",
            "Epoch 2/10 loss 0.33368 val_loss 0.33368 \n",
            "Epoch 2/10 loss 0.81935 val_loss 0.81935 \n",
            "Epoch 2/10 loss 0.83544 val_loss 0.83544 \n",
            "Epoch 2/10 loss 1.41523 val_loss 1.41523 \n",
            "Epoch 2/10 loss -0.25831 val_loss -0.25831 \n",
            "Epoch 2/10 loss -0.29360 val_loss -0.29360 \n",
            "Epoch 2/10 loss 2.70403 val_loss 2.70403 \n",
            "Epoch 2/10 loss 0.84681 val_loss 0.84681 \n",
            "Epoch 2/10 loss 0.82873 val_loss 0.82873 \n",
            "Epoch 2/10 loss 1.27951 val_loss 1.27951 \n",
            "Epoch 2/10 loss -0.42098 val_loss -0.42098 \n",
            "Epoch 2/10 loss 1.80723 val_loss 1.80723 \n",
            "Epoch 2/10 loss 0.45372 val_loss 0.45372 \n",
            "Epoch 2/10 loss 0.47482 val_loss 0.47482 \n",
            "Epoch 2/10 loss 1.22276 val_loss 1.22276 \n",
            "Epoch 2/10 loss 0.73759 val_loss 0.73759 \n",
            "Epoch 2/10 loss 0.61358 val_loss 0.61358 \n",
            "Epoch 2/10 loss 0.32288 val_loss 0.32288 \n",
            "Epoch 2/10 loss 1.12476 val_loss 1.12476 \n",
            "Epoch 2/10 loss 1.23133 val_loss 1.23133 \n",
            "Epoch 2/10 loss 1.81277 val_loss 1.81277 \n",
            "Epoch 2/10 loss 1.26885 val_loss 1.26885 \n",
            "Epoch 2/10 loss 2.87107 val_loss 2.87107 \n",
            "Epoch 2/10 loss 0.99826 val_loss 0.99826 \n",
            "Epoch 2/10 loss 0.73157 val_loss 0.73157 \n",
            "Epoch 2/10 loss 1.01010 val_loss 1.01010 \n",
            "Epoch 2/10 loss 0.72732 val_loss 0.72732 \n",
            "Epoch 2/10 loss 0.36659 val_loss 0.36659 \n",
            "Epoch 2/10 loss 2.25919 val_loss 2.25919 \n",
            "Epoch 2/10 loss -0.21444 val_loss -0.21444 \n",
            "Epoch 2/10 loss 0.82621 val_loss 0.82621 \n",
            "Epoch 2/10 loss 1.40413 val_loss 1.40413 \n",
            "Epoch 2/10 loss 0.84992 val_loss 0.84992 \n",
            "Epoch 2/10 loss 0.25318 val_loss 0.25318 \n",
            "Epoch 2/10 loss 1.76733 val_loss 1.76733 \n",
            "Epoch 2/10 loss 1.67509 val_loss 1.67509 \n",
            "Epoch 2/10 loss -0.28519 val_loss -0.28519 \n",
            "Epoch 2/10 loss 0.42633 val_loss 0.42633 \n",
            "Epoch 2/10 loss 0.17720 val_loss 0.17720 \n",
            "Epoch 2/10 loss 0.42775 val_loss 0.42775 \n",
            "Epoch 2/10 loss 0.75237 val_loss 0.75237 \n",
            "Epoch 2/10 loss -0.31821 val_loss -0.31821 \n",
            "Epoch 2/10 loss -0.16769 val_loss -0.16769 \n",
            "Epoch 2/10 loss 0.24185 val_loss 0.24185 \n",
            "Epoch 2/10 loss 2.29413 val_loss 2.29413 \n",
            "Epoch 2/10 loss 2.42897 val_loss 2.42897 \n",
            "Epoch 2/10 loss 0.93598 val_loss 0.93598 \n",
            "Epoch 2/10 loss -1.19842 val_loss -1.19842 \n",
            "Epoch 2/10 loss 0.21069 val_loss 0.21069 \n",
            "Epoch 2/10 loss 0.90861 val_loss 0.90861 \n",
            "Epoch 2/10 loss 3.15809 val_loss 3.15809 \n",
            "Epoch 2/10 loss 0.22050 val_loss 0.22050 \n",
            "Epoch 2/10 loss 0.21469 val_loss 0.21469 \n",
            "Epoch 2/10 loss -2.21082 val_loss -2.21082 \n",
            "Epoch 2/10 loss 2.20645 val_loss 2.20645 \n",
            "Epoch 2/10 loss 2.13564 val_loss 2.13564 \n",
            "Epoch 2/10 loss 0.87476 val_loss 0.87476 \n",
            "Epoch 2/10 loss -0.81549 val_loss -0.81549 \n",
            "Epoch 2/10 loss 0.28556 val_loss 0.28556 \n",
            "Epoch 2/10 loss -0.84244 val_loss -0.84244 \n",
            "Epoch 2/10 loss -1.31494 val_loss -1.31494 \n",
            "Epoch 2/10 loss 0.94208 val_loss 0.94208 \n",
            "Epoch 2/10 loss 1.02778 val_loss 1.02778 \n",
            "Epoch 2/10 loss -1.94445 val_loss -1.94445 \n",
            "Epoch 2/10 loss -2.02388 val_loss -2.02388 \n",
            "Epoch 2/10 loss -1.27371 val_loss -1.27371 \n",
            "Epoch 2/10 loss -1.51614 val_loss -1.51614 \n",
            "Epoch 2/10 loss 0.02945 val_loss 0.02945 \n",
            "Epoch 2/10 loss 0.01223 val_loss 0.01223 \n",
            "Epoch 3/10 loss -2.10226 val_loss -2.10226 \n",
            "Epoch 3/10 loss -6.86484 val_loss -6.86484 \n",
            "Epoch 3/10 loss 5.06725 val_loss 5.06725 \n",
            "Epoch 3/10 loss 0.00441 val_loss 0.00441 \n",
            "Epoch 3/10 loss 2.88457 val_loss 2.88457 \n",
            "Epoch 3/10 loss 5.95856 val_loss 5.95856 \n",
            "Epoch 3/10 loss 11.99081 val_loss 11.99081 \n",
            "Epoch 3/10 loss 11.74719 val_loss 11.74719 \n",
            "Epoch 3/10 loss 8.28585 val_loss 8.28585 \n",
            "Epoch 3/10 loss -2.51592 val_loss -2.51592 \n",
            "Epoch 3/10 loss -0.01610 val_loss -0.01610 \n",
            "Epoch 3/10 loss 0.00770 val_loss 0.00770 \n",
            "Epoch 3/10 loss -1.94851 val_loss -1.94851 \n",
            "Epoch 3/10 loss 0.00405 val_loss 0.00405 \n",
            "Epoch 3/10 loss 0.01017 val_loss 0.01017 \n",
            "Epoch 3/10 loss 0.01998 val_loss 0.01998 \n",
            "Epoch 3/10 loss 4.99209 val_loss 4.99209 \n",
            "Epoch 3/10 loss 0.04684 val_loss 0.04684 \n",
            "Epoch 3/10 loss 0.04561 val_loss 0.04561 \n",
            "Epoch 3/10 loss -5.15133 val_loss -5.15133 \n",
            "Epoch 3/10 loss 0.06605 val_loss 0.06605 \n",
            "Epoch 3/10 loss -2.58617 val_loss -2.58617 \n",
            "Epoch 3/10 loss 1.44822 val_loss 1.44822 \n",
            "Epoch 3/10 loss 5.68295 val_loss 5.68295 \n",
            "Epoch 3/10 loss 5.46301 val_loss 5.46301 \n",
            "Epoch 3/10 loss 1.29646 val_loss 1.29646 \n",
            "Epoch 3/10 loss -0.90316 val_loss -0.90316 \n",
            "Epoch 3/10 loss -3.61583 val_loss -3.61583 \n",
            "Epoch 3/10 loss 1.02550 val_loss 1.02550 \n",
            "Epoch 3/10 loss -0.78526 val_loss -0.78526 \n",
            "Epoch 3/10 loss 2.84948 val_loss 2.84948 \n",
            "Epoch 3/10 loss 2.75744 val_loss 2.75744 \n",
            "Epoch 3/10 loss -0.55821 val_loss -0.55821 \n",
            "Epoch 3/10 loss 2.95336 val_loss 2.95336 \n",
            "Epoch 3/10 loss 0.32139 val_loss 0.32139 \n",
            "Epoch 3/10 loss 1.84323 val_loss 1.84323 \n",
            "Epoch 3/10 loss 0.02383 val_loss 0.02383 \n",
            "Epoch 3/10 loss 0.56482 val_loss 0.56482 \n",
            "Epoch 3/10 loss 0.55901 val_loss 0.55901 \n",
            "Epoch 3/10 loss 0.73955 val_loss 0.73955 \n",
            "Epoch 3/10 loss 0.66788 val_loss 0.66788 \n",
            "Epoch 3/10 loss 0.64122 val_loss 0.64122 \n",
            "Epoch 3/10 loss 0.74390 val_loss 0.74390 \n",
            "Epoch 3/10 loss 0.53270 val_loss 0.53270 \n",
            "Epoch 3/10 loss 0.19775 val_loss 0.19775 \n",
            "Epoch 3/10 loss 0.93639 val_loss 0.93639 \n",
            "Epoch 3/10 loss 0.79258 val_loss 0.79258 \n",
            "Epoch 3/10 loss 1.09073 val_loss 1.09073 \n",
            "Epoch 3/10 loss 0.38259 val_loss 0.38259 \n",
            "Epoch 3/10 loss 2.38049 val_loss 2.38049 \n",
            "Epoch 3/10 loss 0.03478 val_loss 0.03478 \n",
            "Epoch 3/10 loss 0.95479 val_loss 0.95479 \n",
            "Epoch 3/10 loss 1.64097 val_loss 1.64097 \n",
            "Epoch 3/10 loss 0.90456 val_loss 0.90456 \n",
            "Epoch 3/10 loss 0.50529 val_loss 0.50529 \n",
            "Epoch 3/10 loss -0.50808 val_loss -0.50808 \n",
            "Epoch 3/10 loss -1.59647 val_loss -1.59647 \n",
            "Epoch 3/10 loss -2.60510 val_loss -2.60510 \n",
            "Epoch 3/10 loss -0.10542 val_loss -0.10542 \n",
            "Epoch 3/10 loss -4.97087 val_loss -4.97087 \n",
            "Epoch 3/10 loss 2.07324 val_loss 2.07324 \n",
            "Epoch 3/10 loss 6.99126 val_loss 6.99126 \n",
            "Epoch 3/10 loss 7.66003 val_loss 7.66003 \n",
            "Epoch 3/10 loss -10.68340 val_loss -10.68340 \n",
            "Epoch 3/10 loss -0.00799 val_loss -0.00799 \n",
            "Epoch 3/10 loss 2.97495 val_loss 2.97495 \n",
            "Epoch 3/10 loss 3.20971 val_loss 3.20971 \n",
            "Epoch 3/10 loss 6.63644 val_loss 6.63644 \n",
            "Epoch 3/10 loss 0.00121 val_loss 0.00121 \n",
            "Epoch 3/10 loss 10.05641 val_loss 10.05641 \n",
            "Epoch 3/10 loss 6.62561 val_loss 6.62561 \n",
            "Epoch 3/10 loss 3.24565 val_loss 3.24565 \n",
            "Epoch 3/10 loss 9.01943 val_loss 9.01943 \n",
            "Epoch 3/10 loss 0.00270 val_loss 0.00270 \n",
            "Epoch 3/10 loss -2.80362 val_loss -2.80362 \n",
            "Epoch 3/10 loss -5.29259 val_loss -5.29259 \n",
            "Epoch 3/10 loss -4.80171 val_loss -4.80171 \n",
            "Epoch 3/10 loss -2.57217 val_loss -2.57217 \n",
            "Epoch 3/10 loss -2.60544 val_loss -2.60544 \n",
            "Epoch 3/10 loss -2.71912 val_loss -2.71912 \n",
            "Epoch 3/10 loss 11.14896 val_loss 11.14896 \n",
            "Epoch 3/10 loss 5.43125 val_loss 5.43125 \n",
            "Epoch 3/10 loss -7.97015 val_loss -7.97015 \n",
            "Epoch 3/10 loss -5.28458 val_loss -5.28458 \n",
            "Epoch 3/10 loss -8.02246 val_loss -8.02246 \n",
            "Epoch 3/10 loss 8.45800 val_loss 8.45800 \n",
            "Epoch 3/10 loss 8.60864 val_loss 8.60864 \n",
            "Epoch 3/10 loss -2.81697 val_loss -2.81697 \n",
            "Epoch 3/10 loss 2.82086 val_loss 2.82086 \n",
            "Epoch 3/10 loss -5.54849 val_loss -5.54849 \n",
            "Epoch 3/10 loss 10.71775 val_loss 10.71775 \n",
            "Epoch 3/10 loss 5.42252 val_loss 5.42252 \n",
            "Epoch 3/10 loss 2.57368 val_loss 2.57368 \n",
            "Epoch 3/10 loss -0.23183 val_loss -0.23183 \n",
            "Epoch 3/10 loss -4.67070 val_loss -4.67070 \n",
            "Epoch 3/10 loss 0.04967 val_loss 0.04967 \n",
            "Epoch 3/10 loss 4.34330 val_loss 4.34330 \n",
            "Epoch 3/10 loss -4.24037 val_loss -4.24037 \n",
            "Epoch 3/10 loss -8.03613 val_loss -8.03613 \n",
            "Epoch 3/10 loss 0.01331 val_loss 0.01331 \n",
            "Epoch 3/10 loss 6.08191 val_loss 6.08191 \n",
            "Epoch 3/10 loss 6.51747 val_loss 6.51747 \n",
            "Epoch 3/10 loss 2.08583 val_loss 2.08583 \n",
            "Epoch 3/10 loss -0.01265 val_loss -0.01265 \n",
            "Epoch 3/10 loss -1.87215 val_loss -1.87215 \n",
            "Epoch 3/10 loss -5.60469 val_loss -5.60469 \n",
            "Epoch 3/10 loss 0.03375 val_loss 0.03375 \n",
            "Epoch 3/10 loss 5.71949 val_loss 5.71949 \n",
            "Epoch 3/10 loss -3.66169 val_loss -3.66169 \n",
            "Epoch 3/10 loss 5.20309 val_loss 5.20309 \n",
            "Epoch 3/10 loss 3.59242 val_loss 3.59242 \n",
            "Epoch 3/10 loss -1.67669 val_loss -1.67669 \n",
            "Epoch 3/10 loss 1.62994 val_loss 1.62994 \n",
            "Epoch 3/10 loss 3.03851 val_loss 3.03851 \n",
            "Epoch 3/10 loss -4.13874 val_loss -4.13874 \n",
            "Epoch 3/10 loss -2.64478 val_loss -2.64478 \n",
            "Epoch 3/10 loss 2.35928 val_loss 2.35928 \n",
            "Epoch 3/10 loss 3.79817 val_loss 3.79817 \n",
            "Epoch 3/10 loss 0.16093 val_loss 0.16093 \n",
            "Epoch 3/10 loss 3.15122 val_loss 3.15122 \n",
            "Epoch 3/10 loss 0.09311 val_loss 0.09311 \n",
            "Epoch 3/10 loss -3.44656 val_loss -3.44656 \n",
            "Epoch 3/10 loss -0.83478 val_loss -0.83478 \n",
            "Epoch 3/10 loss -3.33855 val_loss -3.33855 \n",
            "Epoch 3/10 loss -1.04280 val_loss -1.04280 \n",
            "Epoch 3/10 loss -1.23318 val_loss -1.23318 \n",
            "Epoch 3/10 loss 5.36460 val_loss 5.36460 \n",
            "Epoch 3/10 loss 1.54041 val_loss 1.54041 \n",
            "Epoch 3/10 loss 5.99558 val_loss 5.99558 \n",
            "Epoch 3/10 loss 4.42336 val_loss 4.42336 \n",
            "Epoch 3/10 loss -0.54451 val_loss -0.54451 \n",
            "Epoch 3/10 loss 2.49337 val_loss 2.49337 \n",
            "Epoch 3/10 loss 1.99217 val_loss 1.99217 \n",
            "Epoch 3/10 loss 1.03662 val_loss 1.03662 \n",
            "Epoch 3/10 loss 2.29955 val_loss 2.29955 \n",
            "Epoch 3/10 loss 1.27716 val_loss 1.27716 \n",
            "Epoch 3/10 loss 0.71223 val_loss 0.71223 \n",
            "Epoch 3/10 loss 0.60794 val_loss 0.60794 \n",
            "Epoch 3/10 loss 0.92149 val_loss 0.92149 \n",
            "Epoch 3/10 loss 0.67932 val_loss 0.67932 \n",
            "Epoch 3/10 loss 0.24220 val_loss 0.24220 \n",
            "Epoch 3/10 loss 0.73202 val_loss 0.73202 \n",
            "Epoch 3/10 loss -0.16621 val_loss -0.16621 \n",
            "Epoch 3/10 loss 0.93317 val_loss 0.93317 \n",
            "Epoch 3/10 loss 1.44867 val_loss 1.44867 \n",
            "Epoch 3/10 loss 2.90951 val_loss 2.90951 \n",
            "Epoch 3/10 loss 1.44712 val_loss 1.44712 \n",
            "Epoch 3/10 loss 1.35894 val_loss 1.35894 \n",
            "Epoch 3/10 loss 0.78408 val_loss 0.78408 \n",
            "Epoch 3/10 loss 0.82600 val_loss 0.82600 \n",
            "Epoch 4/10 loss 0.80523 val_loss 0.80523 \n",
            "Epoch 4/10 loss 0.54806 val_loss 0.54806 \n",
            "Epoch 4/10 loss 0.54024 val_loss 0.54024 \n",
            "Epoch 4/10 loss 0.31702 val_loss 0.31702 \n",
            "Epoch 4/10 loss 1.06356 val_loss 1.06356 \n",
            "Epoch 4/10 loss -0.58698 val_loss -0.58698 \n",
            "Epoch 4/10 loss -2.24876 val_loss -2.24876 \n",
            "Epoch 4/10 loss 0.96508 val_loss 0.96508 \n",
            "Epoch 4/10 loss 2.23964 val_loss 2.23964 \n",
            "Epoch 4/10 loss 2.50086 val_loss 2.50086 \n",
            "Epoch 4/10 loss 2.64752 val_loss 2.64752 \n",
            "Epoch 4/10 loss -2.51789 val_loss -2.51789 \n",
            "Epoch 4/10 loss 0.05979 val_loss 0.05979 \n",
            "Epoch 4/10 loss 2.63322 val_loss 2.63322 \n",
            "Epoch 4/10 loss 1.52596 val_loss 1.52596 \n",
            "Epoch 4/10 loss 2.93134 val_loss 2.93134 \n",
            "Epoch 4/10 loss -2.78205 val_loss -2.78205 \n",
            "Epoch 4/10 loss -5.61161 val_loss -5.61161 \n",
            "Epoch 4/10 loss 6.09780 val_loss 6.09780 \n",
            "Epoch 4/10 loss -1.58176 val_loss -1.58176 \n",
            "Epoch 4/10 loss -6.39139 val_loss -6.39139 \n",
            "Epoch 4/10 loss 0.00699 val_loss 0.00699 \n",
            "Epoch 4/10 loss 0.04050 val_loss 0.04050 \n",
            "Epoch 4/10 loss -0.05639 val_loss -0.05639 \n",
            "Epoch 4/10 loss -2.03587 val_loss -2.03587 \n",
            "Epoch 4/10 loss 0.01391 val_loss 0.01391 \n",
            "Epoch 4/10 loss 3.38263 val_loss 3.38263 \n",
            "Epoch 4/10 loss -2.11285 val_loss -2.11285 \n",
            "Epoch 4/10 loss 5.98328 val_loss 5.98328 \n",
            "Epoch 4/10 loss -0.14342 val_loss -0.14342 \n",
            "Epoch 4/10 loss 3.55243 val_loss 3.55243 \n",
            "Epoch 4/10 loss 6.72727 val_loss 6.72727 \n",
            "Epoch 4/10 loss 0.02249 val_loss 0.02249 \n",
            "Epoch 4/10 loss 7.64872 val_loss 7.64872 \n",
            "Epoch 4/10 loss 1.64682 val_loss 1.64682 \n",
            "Epoch 4/10 loss 0.97645 val_loss 0.97645 \n",
            "Epoch 4/10 loss 0.76276 val_loss 0.76276 \n",
            "Epoch 4/10 loss 2.30738 val_loss 2.30738 \n",
            "Epoch 4/10 loss 0.55799 val_loss 0.55799 \n",
            "Epoch 4/10 loss -1.04144 val_loss -1.04144 \n",
            "Epoch 4/10 loss 0.77902 val_loss 0.77902 \n",
            "Epoch 4/10 loss 0.60146 val_loss 0.60146 \n",
            "Epoch 4/10 loss 0.68218 val_loss 0.68218 \n",
            "Epoch 4/10 loss 0.62220 val_loss 0.62220 \n",
            "Epoch 4/10 loss 0.56966 val_loss 0.56966 \n",
            "Epoch 4/10 loss 0.93685 val_loss 0.93685 \n",
            "Epoch 4/10 loss 0.49605 val_loss 0.49605 \n",
            "Epoch 4/10 loss 0.51700 val_loss 0.51700 \n",
            "Epoch 4/10 loss 0.90030 val_loss 0.90030 \n",
            "Epoch 4/10 loss 0.65350 val_loss 0.65350 \n",
            "Epoch 4/10 loss 1.32887 val_loss 1.32887 \n",
            "Epoch 4/10 loss 2.09399 val_loss 2.09399 \n",
            "Epoch 4/10 loss 0.36910 val_loss 0.36910 \n",
            "Epoch 4/10 loss 0.57169 val_loss 0.57169 \n",
            "Epoch 4/10 loss 0.57815 val_loss 0.57815 \n",
            "Epoch 4/10 loss 1.33973 val_loss 1.33973 \n",
            "Epoch 4/10 loss 0.79397 val_loss 0.79397 \n",
            "Epoch 4/10 loss 0.59186 val_loss 0.59186 \n",
            "Epoch 4/10 loss 0.01933 val_loss 0.01933 \n",
            "Epoch 4/10 loss -0.74637 val_loss -0.74637 \n",
            "Epoch 4/10 loss 2.71929 val_loss 2.71929 \n",
            "Epoch 4/10 loss -2.02070 val_loss -2.02070 \n",
            "Epoch 4/10 loss 1.93128 val_loss 1.93128 \n",
            "Epoch 4/10 loss 0.16449 val_loss 0.16449 \n",
            "Epoch 4/10 loss -3.45411 val_loss -3.45411 \n",
            "Epoch 4/10 loss -0.02689 val_loss -0.02689 \n",
            "Epoch 4/10 loss -5.93829 val_loss -5.93829 \n",
            "Epoch 4/10 loss 5.26336 val_loss 5.26336 \n",
            "Epoch 4/10 loss 7.32295 val_loss 7.32295 \n",
            "Epoch 4/10 loss -0.05818 val_loss -0.05818 \n",
            "Epoch 4/10 loss 0.03444 val_loss 0.03444 \n",
            "Epoch 4/10 loss -8.23731 val_loss -8.23731 \n",
            "Epoch 4/10 loss -4.33484 val_loss -4.33484 \n",
            "Epoch 4/10 loss 6.54993 val_loss 6.54993 \n",
            "Epoch 4/10 loss -4.59835 val_loss -4.59835 \n",
            "Epoch 4/10 loss 2.36790 val_loss 2.36790 \n",
            "Epoch 4/10 loss 7.47648 val_loss 7.47648 \n",
            "Epoch 4/10 loss -0.20207 val_loss -0.20207 \n",
            "Epoch 4/10 loss 9.94929 val_loss 9.94929 \n",
            "Epoch 4/10 loss -0.17411 val_loss -0.17411 \n",
            "Epoch 4/10 loss -2.33676 val_loss -2.33676 \n",
            "Epoch 4/10 loss 4.57382 val_loss 4.57382 \n",
            "Epoch 4/10 loss -4.29924 val_loss -4.29924 \n",
            "Epoch 4/10 loss 6.24172 val_loss 6.24172 \n",
            "Epoch 4/10 loss 0.03994 val_loss 0.03994 \n",
            "Epoch 4/10 loss -1.99086 val_loss -1.99086 \n",
            "Epoch 4/10 loss 5.59057 val_loss 5.59057 \n",
            "Epoch 4/10 loss -1.75204 val_loss -1.75204 \n",
            "Epoch 4/10 loss 3.32764 val_loss 3.32764 \n",
            "Epoch 4/10 loss -1.53120 val_loss -1.53120 \n",
            "Epoch 4/10 loss -2.95445 val_loss -2.95445 \n",
            "Epoch 4/10 loss 2.89001 val_loss 2.89001 \n",
            "Epoch 4/10 loss -2.89625 val_loss -2.89625 \n",
            "Epoch 4/10 loss 6.05807 val_loss 6.05807 \n",
            "Epoch 4/10 loss -3.03219 val_loss -3.03219 \n",
            "Epoch 4/10 loss -1.15098 val_loss -1.15098 \n",
            "Epoch 4/10 loss -2.70142 val_loss -2.70142 \n",
            "Epoch 4/10 loss 1.37022 val_loss 1.37022 \n",
            "Epoch 4/10 loss 4.03486 val_loss 4.03486 \n",
            "Epoch 4/10 loss -0.13026 val_loss -0.13026 \n",
            "Epoch 4/10 loss -2.31330 val_loss -2.31330 \n",
            "Epoch 4/10 loss -0.09812 val_loss -0.09812 \n",
            "Epoch 4/10 loss -2.57264 val_loss -2.57264 \n",
            "Epoch 4/10 loss -1.24247 val_loss -1.24247 \n",
            "Epoch 4/10 loss -0.07843 val_loss -0.07843 \n",
            "Epoch 4/10 loss -4.32644 val_loss -4.32644 \n",
            "Epoch 4/10 loss 1.15443 val_loss 1.15443 \n",
            "Epoch 4/10 loss 1.27139 val_loss 1.27139 \n",
            "Epoch 4/10 loss 7.71186 val_loss 7.71186 \n",
            "Epoch 4/10 loss 7.65515 val_loss 7.65515 \n",
            "Epoch 4/10 loss -5.31422 val_loss -5.31422 \n",
            "Epoch 4/10 loss -5.28152 val_loss -5.28152 \n",
            "Epoch 4/10 loss 3.16433 val_loss 3.16433 \n",
            "Epoch 4/10 loss 3.33104 val_loss 3.33104 \n",
            "Epoch 4/10 loss -0.53993 val_loss -0.53993 \n",
            "Epoch 4/10 loss -0.31638 val_loss -0.31638 \n",
            "Epoch 4/10 loss 3.07244 val_loss 3.07244 \n",
            "Epoch 4/10 loss 5.09556 val_loss 5.09556 \n",
            "Epoch 4/10 loss 0.09846 val_loss 0.09846 \n",
            "Epoch 4/10 loss 1.22152 val_loss 1.22152 \n",
            "Epoch 4/10 loss -3.64875 val_loss -3.64875 \n",
            "Epoch 4/10 loss 1.60763 val_loss 1.60763 \n",
            "Epoch 4/10 loss -2.63056 val_loss -2.63056 \n",
            "Epoch 4/10 loss 1.01874 val_loss 1.01874 \n",
            "Epoch 4/10 loss -2.21714 val_loss -2.21714 \n",
            "Epoch 4/10 loss 2.07774 val_loss 2.07774 \n",
            "Epoch 4/10 loss 2.24485 val_loss 2.24485 \n",
            "Epoch 4/10 loss 0.57652 val_loss 0.57652 \n",
            "Epoch 4/10 loss 0.96795 val_loss 0.96795 \n",
            "Epoch 4/10 loss 2.93600 val_loss 2.93600 \n",
            "Epoch 4/10 loss -0.60451 val_loss -0.60451 \n",
            "Epoch 4/10 loss 1.11064 val_loss 1.11064 \n",
            "Epoch 4/10 loss -0.77569 val_loss -0.77569 \n",
            "Epoch 4/10 loss 1.80659 val_loss 1.80659 \n",
            "Epoch 4/10 loss -2.21067 val_loss -2.21067 \n",
            "Epoch 4/10 loss 0.03724 val_loss 0.03724 \n",
            "Epoch 4/10 loss -0.82447 val_loss -0.82447 \n",
            "Epoch 4/10 loss 2.03375 val_loss 2.03375 \n",
            "Epoch 4/10 loss -1.26165 val_loss -1.26165 \n",
            "Epoch 4/10 loss 3.48898 val_loss 3.48898 \n",
            "Epoch 4/10 loss 3.09428 val_loss 3.09428 \n",
            "Epoch 4/10 loss 0.77423 val_loss 0.77423 \n",
            "Epoch 4/10 loss 0.22267 val_loss 0.22267 \n",
            "Epoch 4/10 loss 0.84053 val_loss 0.84053 \n",
            "Epoch 4/10 loss 1.13487 val_loss 1.13487 \n",
            "Epoch 4/10 loss 0.19148 val_loss 0.19148 \n",
            "Epoch 4/10 loss 0.61361 val_loss 0.61361 \n",
            "Epoch 4/10 loss 1.07260 val_loss 1.07260 \n",
            "Epoch 4/10 loss -0.17384 val_loss -0.17384 \n",
            "Epoch 4/10 loss 0.13309 val_loss 0.13309 \n",
            "Epoch 5/10 loss 1.86535 val_loss 1.86535 \n",
            "Epoch 5/10 loss 0.53639 val_loss 0.53639 \n",
            "Epoch 5/10 loss 1.77029 val_loss 1.77029 \n",
            "Epoch 5/10 loss 2.84409 val_loss 2.84409 \n",
            "Epoch 5/10 loss -1.31243 val_loss -1.31243 \n",
            "Epoch 5/10 loss 0.59936 val_loss 0.59936 \n",
            "Epoch 5/10 loss -1.04892 val_loss -1.04892 \n",
            "Epoch 5/10 loss 2.81141 val_loss 2.81141 \n",
            "Epoch 5/10 loss 2.29363 val_loss 2.29363 \n",
            "Epoch 5/10 loss 2.68230 val_loss 2.68230 \n",
            "Epoch 5/10 loss 1.23762 val_loss 1.23762 \n",
            "Epoch 5/10 loss -1.38296 val_loss -1.38296 \n",
            "Epoch 5/10 loss -0.68387 val_loss -0.68387 \n",
            "Epoch 5/10 loss -0.77580 val_loss -0.77580 \n",
            "Epoch 5/10 loss 0.76649 val_loss 0.76649 \n",
            "Epoch 5/10 loss 0.30100 val_loss 0.30100 \n",
            "Epoch 5/10 loss 1.91166 val_loss 1.91166 \n",
            "Epoch 5/10 loss 0.62200 val_loss 0.62200 \n",
            "Epoch 5/10 loss 1.15685 val_loss 1.15685 \n",
            "Epoch 5/10 loss 1.46330 val_loss 1.46330 \n",
            "Epoch 5/10 loss -0.32878 val_loss -0.32878 \n",
            "Epoch 5/10 loss 0.39909 val_loss 0.39909 \n",
            "Epoch 5/10 loss 0.40946 val_loss 0.40946 \n",
            "Epoch 5/10 loss -0.83220 val_loss -0.83220 \n",
            "Epoch 5/10 loss 0.38857 val_loss 0.38857 \n",
            "Epoch 5/10 loss 0.73754 val_loss 0.73754 \n",
            "Epoch 5/10 loss 0.14278 val_loss 0.14278 \n",
            "Epoch 5/10 loss 0.90504 val_loss 0.90504 \n",
            "Epoch 5/10 loss 0.95549 val_loss 0.95549 \n",
            "Epoch 5/10 loss -0.46860 val_loss -0.46860 \n",
            "Epoch 5/10 loss 0.81257 val_loss 0.81257 \n",
            "Epoch 5/10 loss 2.35459 val_loss 2.35459 \n",
            "Epoch 5/10 loss 0.90979 val_loss 0.90979 \n",
            "Epoch 5/10 loss -0.42584 val_loss -0.42584 \n",
            "Epoch 5/10 loss 0.89714 val_loss 0.89714 \n",
            "Epoch 5/10 loss -0.86966 val_loss -0.86966 \n",
            "Epoch 5/10 loss -0.31565 val_loss -0.31565 \n",
            "Epoch 5/10 loss -0.22066 val_loss -0.22066 \n",
            "Epoch 5/10 loss -3.38253 val_loss -3.38253 \n",
            "Epoch 5/10 loss 0.09975 val_loss 0.09975 \n",
            "Epoch 5/10 loss 3.46245 val_loss 3.46245 \n",
            "Epoch 5/10 loss 1.51969 val_loss 1.51969 \n",
            "Epoch 5/10 loss 2.63637 val_loss 2.63637 \n",
            "Epoch 5/10 loss -0.20946 val_loss -0.20946 \n",
            "Epoch 5/10 loss 4.11125 val_loss 4.11125 \n",
            "Epoch 5/10 loss 0.89436 val_loss 0.89436 \n",
            "Epoch 5/10 loss -0.05799 val_loss -0.05799 \n",
            "Epoch 5/10 loss 3.11211 val_loss 3.11211 \n",
            "Epoch 5/10 loss 1.26757 val_loss 1.26757 \n",
            "Epoch 5/10 loss 0.92018 val_loss 0.92018 \n",
            "Epoch 5/10 loss -1.38605 val_loss -1.38605 \n",
            "Epoch 5/10 loss 0.50418 val_loss 0.50418 \n",
            "Epoch 5/10 loss 0.92527 val_loss 0.92527 \n",
            "Epoch 5/10 loss -0.61853 val_loss -0.61853 \n",
            "Epoch 5/10 loss -0.31756 val_loss -0.31756 \n",
            "Epoch 5/10 loss 0.50953 val_loss 0.50953 \n",
            "Epoch 5/10 loss -0.84223 val_loss -0.84223 \n",
            "Epoch 5/10 loss 0.55447 val_loss 0.55447 \n",
            "Epoch 5/10 loss 0.61219 val_loss 0.61219 \n",
            "Epoch 5/10 loss 1.11760 val_loss 1.11760 \n",
            "Epoch 5/10 loss 0.11606 val_loss 0.11606 \n",
            "Epoch 5/10 loss -1.94233 val_loss -1.94233 \n",
            "Epoch 5/10 loss -0.49112 val_loss -0.49112 \n",
            "Epoch 5/10 loss 1.52216 val_loss 1.52216 \n",
            "Epoch 5/10 loss 1.53807 val_loss 1.53807 \n",
            "Epoch 5/10 loss -6.54702 val_loss -6.54702 \n",
            "Epoch 5/10 loss 5.21708 val_loss 5.21708 \n",
            "Epoch 5/10 loss -5.90075 val_loss -5.90075 \n",
            "Epoch 5/10 loss 6.73827 val_loss 6.73827 \n",
            "Epoch 5/10 loss -1.58370 val_loss -1.58370 \n",
            "Epoch 5/10 loss -2.11764 val_loss -2.11764 \n",
            "Epoch 5/10 loss 2.98611 val_loss 2.98611 \n",
            "Epoch 5/10 loss 4.75900 val_loss 4.75900 \n",
            "Epoch 5/10 loss 6.50805 val_loss 6.50805 \n",
            "Epoch 5/10 loss -2.58243 val_loss -2.58243 \n",
            "Epoch 5/10 loss 0.74107 val_loss 0.74107 \n",
            "Epoch 5/10 loss -1.87949 val_loss -1.87949 \n",
            "Epoch 5/10 loss -3.87242 val_loss -3.87242 \n",
            "Epoch 5/10 loss -2.34408 val_loss -2.34408 \n",
            "Epoch 5/10 loss -0.09885 val_loss -0.09885 \n",
            "Epoch 5/10 loss 3.52609 val_loss 3.52609 \n",
            "Epoch 5/10 loss 3.73692 val_loss 3.73692 \n",
            "Epoch 5/10 loss -1.69070 val_loss -1.69070 \n",
            "Epoch 5/10 loss -1.94941 val_loss -1.94941 \n",
            "Epoch 5/10 loss 1.13248 val_loss 1.13248 \n",
            "Epoch 5/10 loss 0.96674 val_loss 0.96674 \n",
            "Epoch 5/10 loss -2.23739 val_loss -2.23739 \n",
            "Epoch 5/10 loss 1.66514 val_loss 1.66514 \n",
            "Epoch 5/10 loss -0.72807 val_loss -0.72807 \n",
            "Epoch 5/10 loss -4.76709 val_loss -4.76709 \n",
            "Epoch 5/10 loss -4.68180 val_loss -4.68180 \n",
            "Epoch 5/10 loss -1.58151 val_loss -1.58151 \n",
            "Epoch 5/10 loss -4.84966 val_loss -4.84966 \n",
            "Epoch 5/10 loss 2.69350 val_loss 2.69350 \n",
            "Epoch 5/10 loss 0.28412 val_loss 0.28412 \n",
            "Epoch 5/10 loss 5.70023 val_loss 5.70023 \n",
            "Epoch 5/10 loss -12.67740 val_loss -12.67740 \n",
            "Epoch 5/10 loss 6.18783 val_loss 6.18783 \n",
            "Epoch 5/10 loss 9.74299 val_loss 9.74299 \n",
            "Epoch 5/10 loss -0.38109 val_loss -0.38109 \n",
            "Epoch 5/10 loss 3.14020 val_loss 3.14020 \n",
            "Epoch 5/10 loss -1.83357 val_loss -1.83357 \n",
            "Epoch 5/10 loss -3.13316 val_loss -3.13316 \n",
            "Epoch 5/10 loss 3.70854 val_loss 3.70854 \n",
            "Epoch 5/10 loss 12.35037 val_loss 12.35037 \n",
            "Epoch 5/10 loss -3.03890 val_loss -3.03890 \n",
            "Epoch 5/10 loss -7.61184 val_loss -7.61184 \n",
            "Epoch 5/10 loss 2.10631 val_loss 2.10631 \n",
            "Epoch 5/10 loss 7.30875 val_loss 7.30875 \n",
            "Epoch 5/10 loss -2.17274 val_loss -2.17274 \n",
            "Epoch 5/10 loss 0.69945 val_loss 0.69945 \n",
            "Epoch 5/10 loss 2.01671 val_loss 2.01671 \n",
            "Epoch 5/10 loss -0.03248 val_loss -0.03248 \n",
            "Epoch 5/10 loss -1.51906 val_loss -1.51906 \n",
            "Epoch 5/10 loss -0.79747 val_loss -0.79747 \n",
            "Epoch 5/10 loss 6.38879 val_loss 6.38879 \n",
            "Epoch 5/10 loss -1.82878 val_loss -1.82878 \n",
            "Epoch 5/10 loss -1.27642 val_loss -1.27642 \n",
            "Epoch 5/10 loss 0.89033 val_loss 0.89033 \n",
            "Epoch 5/10 loss -0.47552 val_loss -0.47552 \n",
            "Epoch 5/10 loss -2.10854 val_loss -2.10854 \n",
            "Epoch 5/10 loss 3.16508 val_loss 3.16508 \n",
            "Epoch 5/10 loss 0.02283 val_loss 0.02283 \n",
            "Epoch 5/10 loss -2.57248 val_loss -2.57248 \n",
            "Epoch 5/10 loss -3.20309 val_loss -3.20309 \n",
            "Epoch 5/10 loss -1.86801 val_loss -1.86801 \n",
            "Epoch 5/10 loss -1.72944 val_loss -1.72944 \n",
            "Epoch 5/10 loss -4.58782 val_loss -4.58782 \n",
            "Epoch 5/10 loss -0.26637 val_loss -0.26637 \n",
            "Epoch 5/10 loss -2.88741 val_loss -2.88741 \n",
            "Epoch 5/10 loss -1.10988 val_loss -1.10988 \n",
            "Epoch 5/10 loss 6.86900 val_loss 6.86900 \n",
            "Epoch 5/10 loss 8.01229 val_loss 8.01229 \n",
            "Epoch 5/10 loss 0.53529 val_loss 0.53529 \n",
            "Epoch 5/10 loss -3.78933 val_loss -3.78933 \n",
            "Epoch 5/10 loss -4.02815 val_loss -4.02815 \n",
            "Epoch 5/10 loss 4.12906 val_loss 4.12906 \n",
            "Epoch 5/10 loss -8.51517 val_loss -8.51517 \n",
            "Epoch 5/10 loss -2.17983 val_loss -2.17983 \n",
            "Epoch 5/10 loss -2.29813 val_loss -2.29813 \n",
            "Epoch 5/10 loss -4.65529 val_loss -4.65529 \n",
            "Epoch 5/10 loss 11.06789 val_loss 11.06789 \n",
            "Epoch 5/10 loss -8.52495 val_loss -8.52495 \n",
            "Epoch 5/10 loss -19.99079 val_loss -19.99079 \n",
            "Epoch 5/10 loss 0.00987 val_loss 0.00987 \n",
            "Epoch 5/10 loss 3.82068 val_loss 3.82068 \n",
            "Epoch 5/10 loss 12.58269 val_loss 12.58269 \n",
            "Epoch 5/10 loss -16.95899 val_loss -16.95899 \n",
            "Epoch 5/10 loss 5.79624 val_loss 5.79624 \n",
            "Epoch 5/10 loss 1.18907 val_loss 1.18907 \n",
            "Epoch 6/10 loss 5.18143 val_loss 5.18143 \n",
            "Epoch 6/10 loss 14.73203 val_loss 14.73203 \n",
            "Epoch 6/10 loss -2.91095 val_loss -2.91095 \n",
            "Epoch 6/10 loss 1.35717 val_loss 1.35717 \n",
            "Epoch 6/10 loss 2.20107 val_loss 2.20107 \n",
            "Epoch 6/10 loss 0.65410 val_loss 0.65410 \n",
            "Epoch 6/10 loss 0.80050 val_loss 0.80050 \n",
            "Epoch 6/10 loss 1.34685 val_loss 1.34685 \n",
            "Epoch 6/10 loss -0.96189 val_loss -0.96189 \n",
            "Epoch 6/10 loss 3.46092 val_loss 3.46092 \n",
            "Epoch 6/10 loss 1.90112 val_loss 1.90112 \n",
            "Epoch 6/10 loss -0.71933 val_loss -0.71933 \n",
            "Epoch 6/10 loss 1.54032 val_loss 1.54032 \n",
            "Epoch 6/10 loss -1.18734 val_loss -1.18734 \n",
            "Epoch 6/10 loss -1.38985 val_loss -1.38985 \n",
            "Epoch 6/10 loss 1.09108 val_loss 1.09108 \n",
            "Epoch 6/10 loss 0.23630 val_loss 0.23630 \n",
            "Epoch 6/10 loss 0.68922 val_loss 0.68922 \n",
            "Epoch 6/10 loss 0.85551 val_loss 0.85551 \n",
            "Epoch 6/10 loss -0.48182 val_loss -0.48182 \n",
            "Epoch 6/10 loss 0.22393 val_loss 0.22393 \n",
            "Epoch 6/10 loss 1.20538 val_loss 1.20538 \n",
            "Epoch 6/10 loss 3.05862 val_loss 3.05862 \n",
            "Epoch 6/10 loss 0.95105 val_loss 0.95105 \n",
            "Epoch 6/10 loss -1.61185 val_loss -1.61185 \n",
            "Epoch 6/10 loss -1.62381 val_loss -1.62381 \n",
            "Epoch 6/10 loss -2.10382 val_loss -2.10382 \n",
            "Epoch 6/10 loss -2.31457 val_loss -2.31457 \n",
            "Epoch 6/10 loss 3.76807 val_loss 3.76807 \n",
            "Epoch 6/10 loss -3.64528 val_loss -3.64528 \n",
            "Epoch 6/10 loss -2.54734 val_loss -2.54734 \n",
            "Epoch 6/10 loss -4.88820 val_loss -4.88820 \n",
            "Epoch 6/10 loss 6.07415 val_loss 6.07415 \n",
            "Epoch 6/10 loss 6.60884 val_loss 6.60884 \n",
            "Epoch 6/10 loss 2.85588 val_loss 2.85588 \n",
            "Epoch 6/10 loss -8.29741 val_loss -8.29741 \n",
            "Epoch 6/10 loss 0.17526 val_loss 0.17526 \n",
            "Epoch 6/10 loss -8.63393 val_loss -8.63393 \n",
            "Epoch 6/10 loss -6.39130 val_loss -6.39130 \n",
            "Epoch 6/10 loss -5.07633 val_loss -5.07633 \n",
            "Epoch 6/10 loss 2.05191 val_loss 2.05191 \n",
            "Epoch 6/10 loss -7.18543 val_loss -7.18543 \n",
            "Epoch 6/10 loss 8.79083 val_loss 8.79083 \n",
            "Epoch 6/10 loss -3.89572 val_loss -3.89572 \n",
            "Epoch 6/10 loss -15.70915 val_loss -15.70915 \n",
            "Epoch 6/10 loss 13.66366 val_loss 13.66366 \n",
            "Epoch 6/10 loss 2.80603 val_loss 2.80603 \n",
            "Epoch 6/10 loss -3.39881 val_loss -3.39881 \n",
            "Epoch 6/10 loss -6.41854 val_loss -6.41854 \n",
            "Epoch 6/10 loss 5.54577 val_loss 5.54577 \n",
            "Epoch 6/10 loss 14.74344 val_loss 14.74344 \n",
            "Epoch 6/10 loss 5.22904 val_loss 5.22904 \n",
            "Epoch 6/10 loss -13.92088 val_loss -13.92088 \n",
            "Epoch 6/10 loss 13.39924 val_loss 13.39924 \n",
            "Epoch 6/10 loss -8.73897 val_loss -8.73897 \n",
            "Epoch 6/10 loss 10.96452 val_loss 10.96452 \n",
            "Epoch 6/10 loss -9.01481 val_loss -9.01481 \n",
            "Epoch 6/10 loss 12.31530 val_loss 12.31530 \n",
            "Epoch 6/10 loss -0.04424 val_loss -0.04424 \n",
            "Epoch 6/10 loss -4.79024 val_loss -4.79024 \n",
            "Epoch 6/10 loss 11.33679 val_loss 11.33679 \n",
            "Epoch 6/10 loss -7.16691 val_loss -7.16691 \n",
            "Epoch 6/10 loss -3.69171 val_loss -3.69171 \n",
            "Epoch 6/10 loss 8.81627 val_loss 8.81627 \n",
            "Epoch 6/10 loss 0.00871 val_loss 0.00871 \n",
            "Epoch 6/10 loss 1.63588 val_loss 1.63588 \n",
            "Epoch 6/10 loss -7.09080 val_loss -7.09080 \n",
            "Epoch 6/10 loss -9.07381 val_loss -9.07381 \n",
            "Epoch 6/10 loss -6.31000 val_loss -6.31000 \n",
            "Epoch 6/10 loss 3.28191 val_loss 3.28191 \n",
            "Epoch 6/10 loss 3.31992 val_loss 3.31992 \n",
            "Epoch 6/10 loss 5.03995 val_loss 5.03995 \n",
            "Epoch 6/10 loss -2.69370 val_loss -2.69370 \n",
            "Epoch 6/10 loss -14.24948 val_loss -14.24948 \n",
            "Epoch 6/10 loss 14.23019 val_loss 14.23019 \n",
            "Epoch 6/10 loss 6.92042 val_loss 6.92042 \n",
            "Epoch 6/10 loss 0.00929 val_loss 0.00929 \n",
            "Epoch 6/10 loss -6.93626 val_loss -6.93626 \n",
            "Epoch 6/10 loss 6.32541 val_loss 6.32541 \n",
            "Epoch 6/10 loss -10.43114 val_loss -10.43114 \n",
            "Epoch 6/10 loss -2.92762 val_loss -2.92762 \n",
            "Epoch 6/10 loss -5.57492 val_loss -5.57492 \n",
            "Epoch 6/10 loss 1.46204 val_loss 1.46204 \n",
            "Epoch 6/10 loss 3.98677 val_loss 3.98677 \n",
            "Epoch 6/10 loss -2.21186 val_loss -2.21186 \n",
            "Epoch 6/10 loss 5.08359 val_loss 5.08359 \n",
            "Epoch 6/10 loss 7.16168 val_loss 7.16168 \n",
            "Epoch 6/10 loss 10.05725 val_loss 10.05725 \n",
            "Epoch 6/10 loss -2.50168 val_loss -2.50168 \n",
            "Epoch 6/10 loss 4.85956 val_loss 4.85956 \n",
            "Epoch 6/10 loss 2.75896 val_loss 2.75896 \n",
            "Epoch 6/10 loss -5.02300 val_loss -5.02300 \n",
            "Epoch 6/10 loss 0.78098 val_loss 0.78098 \n",
            "Epoch 6/10 loss 5.39781 val_loss 5.39781 \n",
            "Epoch 6/10 loss 7.35325 val_loss 7.35325 \n",
            "Epoch 6/10 loss -2.56461 val_loss -2.56461 \n",
            "Epoch 6/10 loss 1.57227 val_loss 1.57227 \n",
            "Epoch 6/10 loss -3.03943 val_loss -3.03943 \n",
            "Epoch 6/10 loss -0.23886 val_loss -0.23886 \n",
            "Epoch 6/10 loss 0.02278 val_loss 0.02278 \n",
            "Epoch 6/10 loss -0.25579 val_loss -0.25579 \n",
            "Epoch 6/10 loss 1.93053 val_loss 1.93053 \n",
            "Epoch 6/10 loss 4.17737 val_loss 4.17737 \n",
            "Epoch 6/10 loss -0.12489 val_loss -0.12489 \n",
            "Epoch 6/10 loss -0.20383 val_loss -0.20383 \n",
            "Epoch 6/10 loss -8.06819 val_loss -8.06819 \n",
            "Epoch 6/10 loss -2.60737 val_loss -2.60737 \n",
            "Epoch 6/10 loss 0.18755 val_loss 0.18755 \n",
            "Epoch 6/10 loss -3.55469 val_loss -3.55469 \n",
            "Epoch 6/10 loss -0.68476 val_loss -0.68476 \n",
            "Epoch 6/10 loss 1.79420 val_loss 1.79420 \n",
            "Epoch 6/10 loss 2.44403 val_loss 2.44403 \n",
            "Epoch 6/10 loss 2.33721 val_loss 2.33721 \n",
            "Epoch 6/10 loss 2.44706 val_loss 2.44706 \n",
            "Epoch 6/10 loss -3.17420 val_loss -3.17420 \n",
            "Epoch 6/10 loss -3.83077 val_loss -3.83077 \n",
            "Epoch 6/10 loss 0.68548 val_loss 0.68548 \n",
            "Epoch 6/10 loss -3.61637 val_loss -3.61637 \n",
            "Epoch 6/10 loss -0.11288 val_loss -0.11288 \n",
            "Epoch 6/10 loss 4.60165 val_loss 4.60165 \n",
            "Epoch 6/10 loss -7.38716 val_loss -7.38716 \n",
            "Epoch 6/10 loss -3.13851 val_loss -3.13851 \n",
            "Epoch 6/10 loss -10.03347 val_loss -10.03347 \n",
            "Epoch 6/10 loss 8.98138 val_loss 8.98138 \n",
            "Epoch 6/10 loss 6.65090 val_loss 6.65090 \n",
            "Epoch 6/10 loss 3.44653 val_loss 3.44653 \n",
            "Epoch 6/10 loss 14.59251 val_loss 14.59251 \n",
            "Epoch 6/10 loss -4.63900 val_loss -4.63900 \n",
            "Epoch 6/10 loss 1.66852 val_loss 1.66852 \n",
            "Epoch 6/10 loss 6.61305 val_loss 6.61305 \n",
            "Epoch 6/10 loss -8.86759 val_loss -8.86759 \n",
            "Epoch 6/10 loss 16.32186 val_loss 16.32186 \n",
            "Epoch 6/10 loss -4.18127 val_loss -4.18127 \n",
            "Epoch 6/10 loss 4.14868 val_loss 4.14868 \n",
            "Epoch 6/10 loss -2.92915 val_loss -2.92915 \n",
            "Epoch 6/10 loss -3.50202 val_loss -3.50202 \n",
            "Epoch 6/10 loss 0.01805 val_loss 0.01805 \n",
            "Epoch 6/10 loss -7.50695 val_loss -7.50695 \n",
            "Epoch 6/10 loss 2.40972 val_loss 2.40972 \n",
            "Epoch 6/10 loss -3.65419 val_loss -3.65419 \n",
            "Epoch 6/10 loss 2.66672 val_loss 2.66672 \n",
            "Epoch 6/10 loss -2.67571 val_loss -2.67571 \n",
            "Epoch 6/10 loss 9.39945 val_loss 9.39945 \n",
            "Epoch 6/10 loss 0.39523 val_loss 0.39523 \n",
            "Epoch 6/10 loss -3.56113 val_loss -3.56113 \n",
            "Epoch 6/10 loss 1.08231 val_loss 1.08231 \n",
            "Epoch 6/10 loss -1.94061 val_loss -1.94061 \n",
            "Epoch 6/10 loss 0.12518 val_loss 0.12518 \n",
            "Epoch 6/10 loss 1.02210 val_loss 1.02210 \n",
            "Epoch 6/10 loss -3.83547 val_loss -3.83547 \n",
            "Epoch 7/10 loss -4.25640 val_loss -4.25640 \n",
            "Epoch 7/10 loss -3.45727 val_loss -3.45727 \n",
            "Epoch 7/10 loss 0.00473 val_loss 0.00473 \n",
            "Epoch 7/10 loss -4.57450 val_loss -4.57450 \n",
            "Epoch 7/10 loss 0.56532 val_loss 0.56532 \n",
            "Epoch 7/10 loss -5.14706 val_loss -5.14706 \n",
            "Epoch 7/10 loss -13.37181 val_loss -13.37181 \n",
            "Epoch 7/10 loss -0.02494 val_loss -0.02494 \n",
            "Epoch 7/10 loss 8.41644 val_loss 8.41644 \n",
            "Epoch 7/10 loss 6.88995 val_loss 6.88995 \n",
            "Epoch 7/10 loss -4.14920 val_loss -4.14920 \n",
            "Epoch 7/10 loss 1.55613 val_loss 1.55613 \n",
            "Epoch 7/10 loss 3.61721 val_loss 3.61721 \n",
            "Epoch 7/10 loss 4.73040 val_loss 4.73040 \n",
            "Epoch 7/10 loss 3.56845 val_loss 3.56845 \n",
            "Epoch 7/10 loss 3.86394 val_loss 3.86394 \n",
            "Epoch 7/10 loss 0.08655 val_loss 0.08655 \n",
            "Epoch 7/10 loss -1.91264 val_loss -1.91264 \n",
            "Epoch 7/10 loss -2.50883 val_loss -2.50883 \n",
            "Epoch 7/10 loss -3.47663 val_loss -3.47663 \n",
            "Epoch 7/10 loss -5.58396 val_loss -5.58396 \n",
            "Epoch 7/10 loss -4.31869 val_loss -4.31869 \n",
            "Epoch 7/10 loss 6.07904 val_loss 6.07904 \n",
            "Epoch 7/10 loss -5.68271 val_loss -5.68271 \n",
            "Epoch 7/10 loss 2.18246 val_loss 2.18246 \n",
            "Epoch 7/10 loss -1.60843 val_loss -1.60843 \n",
            "Epoch 7/10 loss 6.50747 val_loss 6.50747 \n",
            "Epoch 7/10 loss 8.02098 val_loss 8.02098 \n",
            "Epoch 7/10 loss 1.83431 val_loss 1.83431 \n",
            "Epoch 7/10 loss -7.73859 val_loss -7.73859 \n",
            "Epoch 7/10 loss 10.36032 val_loss 10.36032 \n",
            "Epoch 7/10 loss -1.74644 val_loss -1.74644 \n",
            "Epoch 7/10 loss 6.00741 val_loss 6.00741 \n",
            "Epoch 7/10 loss 1.92532 val_loss 1.92532 \n",
            "Epoch 7/10 loss 6.72979 val_loss 6.72979 \n",
            "Epoch 7/10 loss -2.92938 val_loss -2.92938 \n",
            "Epoch 7/10 loss -4.83329 val_loss -4.83329 \n",
            "Epoch 7/10 loss 5.54474 val_loss 5.54474 \n",
            "Epoch 7/10 loss -4.76018 val_loss -4.76018 \n",
            "Epoch 7/10 loss 6.55156 val_loss 6.55156 \n",
            "Epoch 7/10 loss -2.13338 val_loss -2.13338 \n",
            "Epoch 7/10 loss -6.03995 val_loss -6.03995 \n",
            "Epoch 7/10 loss -2.15728 val_loss -2.15728 \n",
            "Epoch 7/10 loss -2.19627 val_loss -2.19627 \n",
            "Epoch 7/10 loss -2.00828 val_loss -2.00828 \n",
            "Epoch 7/10 loss 6.38486 val_loss 6.38486 \n",
            "Epoch 7/10 loss -2.12852 val_loss -2.12852 \n",
            "Epoch 7/10 loss 3.92783 val_loss 3.92783 \n",
            "Epoch 7/10 loss 0.21799 val_loss 0.21799 \n",
            "Epoch 7/10 loss 3.88867 val_loss 3.88867 \n",
            "Epoch 7/10 loss -5.29323 val_loss -5.29323 \n",
            "Epoch 7/10 loss -4.54377 val_loss -4.54377 \n",
            "Epoch 7/10 loss 2.89057 val_loss 2.89057 \n",
            "Epoch 7/10 loss -4.58051 val_loss -4.58051 \n",
            "Epoch 7/10 loss 0.74419 val_loss 0.74419 \n",
            "Epoch 7/10 loss -5.05102 val_loss -5.05102 \n",
            "Epoch 7/10 loss -4.74782 val_loss -4.74782 \n",
            "Epoch 7/10 loss -3.87535 val_loss -3.87535 \n",
            "Epoch 7/10 loss 0.08003 val_loss 0.08003 \n",
            "Epoch 7/10 loss 1.18631 val_loss 1.18631 \n",
            "Epoch 7/10 loss -4.84386 val_loss -4.84386 \n",
            "Epoch 7/10 loss -0.80036 val_loss -0.80036 \n",
            "Epoch 7/10 loss 8.67797 val_loss 8.67797 \n",
            "Epoch 7/10 loss 6.01354 val_loss 6.01354 \n",
            "Epoch 7/10 loss 5.40727 val_loss 5.40727 \n",
            "Epoch 7/10 loss -0.66678 val_loss -0.66678 \n",
            "Epoch 7/10 loss -10.44059 val_loss -10.44059 \n",
            "Epoch 7/10 loss 2.27167 val_loss 2.27167 \n",
            "Epoch 7/10 loss 5.65633 val_loss 5.65633 \n",
            "Epoch 7/10 loss -3.11993 val_loss -3.11993 \n",
            "Epoch 7/10 loss 0.00359 val_loss 0.00359 \n",
            "Epoch 7/10 loss 4.51676 val_loss 4.51676 \n",
            "Epoch 7/10 loss 0.12112 val_loss 0.12112 \n",
            "Epoch 7/10 loss 5.28855 val_loss 5.28855 \n",
            "Epoch 7/10 loss -4.42165 val_loss -4.42165 \n",
            "Epoch 7/10 loss 3.49758 val_loss 3.49758 \n",
            "Epoch 7/10 loss -1.98813 val_loss -1.98813 \n",
            "Epoch 7/10 loss -1.42179 val_loss -1.42179 \n",
            "Epoch 7/10 loss -5.39315 val_loss -5.39315 \n",
            "Epoch 7/10 loss 0.33390 val_loss 0.33390 \n",
            "Epoch 7/10 loss 0.00211 val_loss 0.00211 \n",
            "Epoch 7/10 loss 1.91874 val_loss 1.91874 \n",
            "Epoch 7/10 loss 2.67658 val_loss 2.67658 \n",
            "Epoch 7/10 loss -3.73055 val_loss -3.73055 \n",
            "Epoch 7/10 loss 2.76158 val_loss 2.76158 \n",
            "Epoch 7/10 loss 1.76254 val_loss 1.76254 \n",
            "Epoch 7/10 loss 5.56316 val_loss 5.56316 \n",
            "Epoch 7/10 loss -4.82730 val_loss -4.82730 \n",
            "Epoch 7/10 loss 1.65996 val_loss 1.65996 \n",
            "Epoch 7/10 loss 2.76031 val_loss 2.76031 \n",
            "Epoch 7/10 loss 4.02268 val_loss 4.02268 \n",
            "Epoch 7/10 loss 6.18576 val_loss 6.18576 \n",
            "Epoch 7/10 loss -2.35192 val_loss -2.35192 \n",
            "Epoch 7/10 loss 3.94344 val_loss 3.94344 \n",
            "Epoch 7/10 loss 2.28972 val_loss 2.28972 \n",
            "Epoch 7/10 loss -8.92636 val_loss -8.92636 \n",
            "Epoch 7/10 loss -5.13700 val_loss -5.13700 \n",
            "Epoch 7/10 loss 0.26301 val_loss 0.26301 \n",
            "Epoch 7/10 loss -5.19884 val_loss -5.19884 \n",
            "Epoch 7/10 loss 5.90140 val_loss 5.90140 \n",
            "Epoch 7/10 loss -7.68387 val_loss -7.68387 \n",
            "Epoch 7/10 loss 5.25565 val_loss 5.25565 \n",
            "Epoch 7/10 loss 8.92326 val_loss 8.92326 \n",
            "Epoch 7/10 loss 7.17519 val_loss 7.17519 \n",
            "Epoch 7/10 loss 3.68229 val_loss 3.68229 \n",
            "Epoch 7/10 loss 1.04348 val_loss 1.04348 \n",
            "Epoch 7/10 loss -7.07770 val_loss -7.07770 \n",
            "Epoch 7/10 loss -2.64164 val_loss -2.64164 \n",
            "Epoch 7/10 loss -5.42302 val_loss -5.42302 \n",
            "Epoch 7/10 loss 3.73934 val_loss 3.73934 \n",
            "Epoch 7/10 loss 1.73264 val_loss 1.73264 \n",
            "Epoch 7/10 loss -1.71940 val_loss -1.71940 \n",
            "Epoch 7/10 loss -11.05378 val_loss -11.05378 \n",
            "Epoch 7/10 loss -7.49206 val_loss -7.49206 \n",
            "Epoch 7/10 loss 0.06032 val_loss 0.06032 \n",
            "Epoch 7/10 loss -2.24456 val_loss -2.24456 \n",
            "Epoch 7/10 loss -8.43696 val_loss -8.43696 \n",
            "Epoch 7/10 loss -2.65376 val_loss -2.65376 \n",
            "Epoch 7/10 loss 4.54381 val_loss 4.54381 \n",
            "Epoch 7/10 loss -9.45673 val_loss -9.45673 \n",
            "Epoch 7/10 loss 9.94639 val_loss 9.94639 \n",
            "Epoch 7/10 loss -5.17451 val_loss -5.17451 \n",
            "Epoch 7/10 loss -1.58768 val_loss -1.58768 \n",
            "Epoch 7/10 loss -10.82142 val_loss -10.82142 \n",
            "Epoch 7/10 loss 8.90720 val_loss 8.90720 \n",
            "Epoch 7/10 loss -17.25150 val_loss -17.25150 \n",
            "Epoch 7/10 loss -5.99530 val_loss -5.99530 \n",
            "Epoch 7/10 loss 5.27705 val_loss 5.27705 \n",
            "Epoch 7/10 loss -6.45380 val_loss -6.45380 \n",
            "Epoch 7/10 loss 11.43899 val_loss 11.43899 \n",
            "Epoch 7/10 loss -13.25317 val_loss -13.25317 \n",
            "Epoch 7/10 loss -1.70691 val_loss -1.70691 \n",
            "Epoch 7/10 loss 8.34677 val_loss 8.34677 \n",
            "Epoch 7/10 loss 20.92916 val_loss 20.92916 \n",
            "Epoch 7/10 loss 11.53283 val_loss 11.53283 \n",
            "Epoch 7/10 loss -1.78572 val_loss -1.78572 \n",
            "Epoch 7/10 loss -0.54110 val_loss -0.54110 \n",
            "Epoch 7/10 loss -6.59808 val_loss -6.59808 \n",
            "Epoch 7/10 loss 15.39619 val_loss 15.39619 \n",
            "Epoch 7/10 loss 1.79936 val_loss 1.79936 \n",
            "Epoch 7/10 loss 6.41749 val_loss 6.41749 \n",
            "Epoch 7/10 loss 11.50917 val_loss 11.50917 \n",
            "Epoch 7/10 loss 9.16241 val_loss 9.16241 \n",
            "Epoch 7/10 loss 9.90387 val_loss 9.90387 \n",
            "Epoch 7/10 loss -7.72537 val_loss -7.72537 \n",
            "Epoch 7/10 loss 2.10546 val_loss 2.10546 \n",
            "Epoch 7/10 loss -5.93815 val_loss -5.93815 \n",
            "Epoch 7/10 loss 0.37832 val_loss 0.37832 \n",
            "Epoch 7/10 loss -0.07066 val_loss -0.07066 \n",
            "Epoch 7/10 loss -7.11489 val_loss -7.11489 \n",
            "Epoch 8/10 loss 6.75445 val_loss 6.75445 \n",
            "Epoch 8/10 loss 9.07558 val_loss 9.07558 \n",
            "Epoch 8/10 loss -0.75248 val_loss -0.75248 \n",
            "Epoch 8/10 loss -2.72679 val_loss -2.72679 \n",
            "Epoch 8/10 loss 2.18260 val_loss 2.18260 \n",
            "Epoch 8/10 loss 0.20192 val_loss 0.20192 \n",
            "Epoch 8/10 loss -4.80486 val_loss -4.80486 \n",
            "Epoch 8/10 loss 0.58209 val_loss 0.58209 \n",
            "Epoch 8/10 loss -0.05562 val_loss -0.05562 \n",
            "Epoch 8/10 loss 7.42944 val_loss 7.42944 \n",
            "Epoch 8/10 loss 0.99584 val_loss 0.99584 \n",
            "Epoch 8/10 loss 8.07753 val_loss 8.07753 \n",
            "Epoch 8/10 loss -0.37000 val_loss -0.37000 \n",
            "Epoch 8/10 loss -4.91601 val_loss -4.91601 \n",
            "Epoch 8/10 loss -2.30170 val_loss -2.30170 \n",
            "Epoch 8/10 loss 2.07000 val_loss 2.07000 \n",
            "Epoch 8/10 loss 7.48417 val_loss 7.48417 \n",
            "Epoch 8/10 loss 0.41097 val_loss 0.41097 \n",
            "Epoch 8/10 loss 1.44024 val_loss 1.44024 \n",
            "Epoch 8/10 loss -1.86582 val_loss -1.86582 \n",
            "Epoch 8/10 loss -3.89263 val_loss -3.89263 \n",
            "Epoch 8/10 loss 5.13750 val_loss 5.13750 \n",
            "Epoch 8/10 loss -1.50788 val_loss -1.50788 \n",
            "Epoch 8/10 loss 1.88104 val_loss 1.88104 \n",
            "Epoch 8/10 loss -1.49787 val_loss -1.49787 \n",
            "Epoch 8/10 loss -4.95587 val_loss -4.95587 \n",
            "Epoch 8/10 loss -3.25279 val_loss -3.25279 \n",
            "Epoch 8/10 loss 1.84188 val_loss 1.84188 \n",
            "Epoch 8/10 loss -3.17981 val_loss -3.17981 \n",
            "Epoch 8/10 loss -3.90405 val_loss -3.90405 \n",
            "Epoch 8/10 loss -4.28803 val_loss -4.28803 \n",
            "Epoch 8/10 loss -2.34089 val_loss -2.34089 \n",
            "Epoch 8/10 loss -1.73328 val_loss -1.73328 \n",
            "Epoch 8/10 loss 6.04175 val_loss 6.04175 \n",
            "Epoch 8/10 loss -0.19828 val_loss -0.19828 \n",
            "Epoch 8/10 loss 4.50010 val_loss 4.50010 \n",
            "Epoch 8/10 loss 1.16612 val_loss 1.16612 \n",
            "Epoch 8/10 loss 4.96777 val_loss 4.96777 \n",
            "Epoch 8/10 loss -1.88344 val_loss -1.88344 \n",
            "Epoch 8/10 loss 5.70168 val_loss 5.70168 \n",
            "Epoch 8/10 loss -9.54953 val_loss -9.54953 \n",
            "Epoch 8/10 loss 7.66741 val_loss 7.66741 \n",
            "Epoch 8/10 loss -10.64410 val_loss -10.64410 \n",
            "Epoch 8/10 loss 7.50475 val_loss 7.50475 \n",
            "Epoch 8/10 loss 5.82024 val_loss 5.82024 \n",
            "Epoch 8/10 loss 2.47413 val_loss 2.47413 \n",
            "Epoch 8/10 loss -3.96054 val_loss -3.96054 \n",
            "Epoch 8/10 loss 7.98749 val_loss 7.98749 \n",
            "Epoch 8/10 loss -3.92008 val_loss -3.92008 \n",
            "Epoch 8/10 loss 0.14294 val_loss 0.14294 \n",
            "Epoch 8/10 loss 7.53848 val_loss 7.53848 \n",
            "Epoch 8/10 loss -12.04904 val_loss -12.04904 \n",
            "Epoch 8/10 loss -8.86614 val_loss -8.86614 \n",
            "Epoch 8/10 loss -3.52314 val_loss -3.52314 \n",
            "Epoch 8/10 loss 5.30897 val_loss 5.30897 \n",
            "Epoch 8/10 loss -8.25439 val_loss -8.25439 \n",
            "Epoch 8/10 loss 5.21750 val_loss 5.21750 \n",
            "Epoch 8/10 loss -19.75808 val_loss -19.75808 \n",
            "Epoch 8/10 loss -12.16875 val_loss -12.16875 \n",
            "Epoch 8/10 loss 9.23061 val_loss 9.23061 \n",
            "Epoch 8/10 loss -5.82956 val_loss -5.82956 \n",
            "Epoch 8/10 loss 5.81593 val_loss 5.81593 \n",
            "Epoch 8/10 loss 6.28635 val_loss 6.28635 \n",
            "Epoch 8/10 loss -6.97009 val_loss -6.97009 \n",
            "Epoch 8/10 loss 18.20671 val_loss 18.20671 \n",
            "Epoch 8/10 loss -6.50004 val_loss -6.50004 \n",
            "Epoch 8/10 loss 13.26449 val_loss 13.26449 \n",
            "Epoch 8/10 loss -20.08041 val_loss -20.08041 \n",
            "Epoch 8/10 loss 9.67690 val_loss 9.67690 \n",
            "Epoch 8/10 loss -13.44246 val_loss -13.44246 \n",
            "Epoch 8/10 loss 5.13373 val_loss 5.13373 \n",
            "Epoch 8/10 loss -5.86889 val_loss -5.86889 \n",
            "Epoch 8/10 loss -21.12168 val_loss -21.12168 \n",
            "Epoch 8/10 loss -21.77179 val_loss -21.77179 \n",
            "Epoch 8/10 loss 7.18961 val_loss 7.18961 \n",
            "Epoch 8/10 loss -5.06509 val_loss -5.06509 \n",
            "Epoch 8/10 loss -15.55469 val_loss -15.55469 \n",
            "Epoch 8/10 loss 11.87861 val_loss 11.87861 \n",
            "Epoch 8/10 loss -16.96850 val_loss -16.96850 \n",
            "Epoch 8/10 loss 8.37651 val_loss 8.37651 \n",
            "Epoch 8/10 loss 0.00000 val_loss 0.00000 \n",
            "Epoch 8/10 loss 24.17026 val_loss 24.17026 \n",
            "Epoch 8/10 loss -3.95368 val_loss -3.95368 \n",
            "Epoch 8/10 loss 17.40207 val_loss 17.40207 \n",
            "Epoch 8/10 loss -10.29878 val_loss -10.29878 \n",
            "Epoch 8/10 loss -0.02027 val_loss -0.02027 \n",
            "Epoch 8/10 loss -2.66286 val_loss -2.66286 \n",
            "Epoch 8/10 loss -23.41562 val_loss -23.41562 \n",
            "Epoch 8/10 loss -3.54374 val_loss -3.54374 \n",
            "Epoch 8/10 loss 23.42515 val_loss 23.42515 \n",
            "Epoch 8/10 loss -18.48620 val_loss -18.48620 \n",
            "Epoch 8/10 loss 35.13250 val_loss 35.13250 \n",
            "Epoch 8/10 loss -8.97554 val_loss -8.97554 \n",
            "Epoch 8/10 loss 17.06616 val_loss 17.06616 \n",
            "Epoch 8/10 loss -35.52118 val_loss -35.52118 \n",
            "Epoch 8/10 loss 4.08019 val_loss 4.08019 \n",
            "Epoch 8/10 loss -15.09693 val_loss -15.09693 \n",
            "Epoch 8/10 loss -14.24664 val_loss -14.24664 \n",
            "Epoch 8/10 loss -18.50124 val_loss -18.50124 \n",
            "Epoch 8/10 loss 9.33637 val_loss 9.33637 \n",
            "Epoch 8/10 loss 21.00384 val_loss 21.00384 \n",
            "Epoch 8/10 loss -0.06111 val_loss -0.06111 \n",
            "Epoch 8/10 loss 22.60580 val_loss 22.60580 \n",
            "Epoch 8/10 loss -14.55091 val_loss -14.55091 \n",
            "Epoch 8/10 loss -15.88853 val_loss -15.88853 \n",
            "Epoch 8/10 loss -9.43141 val_loss -9.43141 \n",
            "Epoch 8/10 loss 9.38844 val_loss 9.38844 \n",
            "Epoch 8/10 loss -9.34385 val_loss -9.34385 \n",
            "Epoch 8/10 loss 13.44606 val_loss 13.44606 \n",
            "Epoch 8/10 loss 20.88909 val_loss 20.88909 \n",
            "Epoch 8/10 loss 1.76806 val_loss 1.76806 \n",
            "Epoch 8/10 loss -27.02658 val_loss -27.02658 \n",
            "Epoch 8/10 loss 0.34206 val_loss 0.34206 \n",
            "Epoch 8/10 loss -14.13189 val_loss -14.13189 \n",
            "Epoch 8/10 loss 1.32553 val_loss 1.32553 \n",
            "Epoch 8/10 loss 19.34031 val_loss 19.34031 \n",
            "Epoch 8/10 loss 15.58575 val_loss 15.58575 \n",
            "Epoch 8/10 loss 8.72374 val_loss 8.72374 \n",
            "Epoch 8/10 loss 0.66790 val_loss 0.66790 \n",
            "Epoch 8/10 loss 14.29128 val_loss 14.29128 \n",
            "Epoch 8/10 loss -15.45131 val_loss -15.45131 \n",
            "Epoch 8/10 loss 2.68887 val_loss 2.68887 \n",
            "Epoch 8/10 loss 9.32506 val_loss 9.32506 \n",
            "Epoch 8/10 loss 7.44693 val_loss 7.44693 \n",
            "Epoch 8/10 loss -3.47746 val_loss -3.47746 \n",
            "Epoch 8/10 loss 3.19798 val_loss 3.19798 \n",
            "Epoch 8/10 loss 0.20710 val_loss 0.20710 \n",
            "Epoch 8/10 loss 0.32956 val_loss 0.32956 \n",
            "Epoch 8/10 loss 1.34331 val_loss 1.34331 \n",
            "Epoch 8/10 loss 2.07925 val_loss 2.07925 \n",
            "Epoch 8/10 loss -0.34201 val_loss -0.34201 \n",
            "Epoch 8/10 loss 0.86166 val_loss 0.86166 \n",
            "Epoch 8/10 loss -0.42111 val_loss -0.42111 \n",
            "Epoch 8/10 loss 0.26487 val_loss 0.26487 \n",
            "Epoch 8/10 loss -0.00308 val_loss -0.00308 \n",
            "Epoch 8/10 loss 0.11247 val_loss 0.11247 \n",
            "Epoch 8/10 loss -1.31642 val_loss -1.31642 \n",
            "Epoch 8/10 loss -4.49784 val_loss -4.49784 \n",
            "Epoch 8/10 loss -3.03666 val_loss -3.03666 \n",
            "Epoch 8/10 loss -0.93686 val_loss -0.93686 \n",
            "Epoch 8/10 loss 1.32873 val_loss 1.32873 \n",
            "Epoch 8/10 loss -0.19754 val_loss -0.19754 \n",
            "Epoch 8/10 loss -0.72020 val_loss -0.72020 \n",
            "Epoch 8/10 loss 0.17122 val_loss 0.17122 \n",
            "Epoch 8/10 loss 0.01756 val_loss 0.01756 \n",
            "Epoch 8/10 loss 4.94666 val_loss 4.94666 \n",
            "Epoch 8/10 loss -5.04095 val_loss -5.04095 \n",
            "Epoch 8/10 loss -5.36407 val_loss -5.36407 \n",
            "Epoch 8/10 loss -7.51232 val_loss -7.51232 \n",
            "Epoch 8/10 loss -5.32257 val_loss -5.32257 \n",
            "Epoch 9/10 loss -3.84497 val_loss -3.84497 \n",
            "Epoch 9/10 loss -3.56531 val_loss -3.56531 \n",
            "Epoch 9/10 loss -9.94812 val_loss -9.94812 \n",
            "Epoch 9/10 loss -13.71086 val_loss -13.71086 \n",
            "Epoch 9/10 loss -2.56197 val_loss -2.56197 \n",
            "Epoch 9/10 loss -5.28517 val_loss -5.28517 \n",
            "Epoch 9/10 loss 2.47059 val_loss 2.47059 \n",
            "Epoch 9/10 loss -9.67282 val_loss -9.67282 \n",
            "Epoch 9/10 loss -5.68992 val_loss -5.68992 \n",
            "Epoch 9/10 loss -5.17378 val_loss -5.17378 \n",
            "Epoch 9/10 loss -1.94050 val_loss -1.94050 \n",
            "Epoch 9/10 loss -5.73616 val_loss -5.73616 \n",
            "Epoch 9/10 loss 5.98034 val_loss 5.98034 \n",
            "Epoch 9/10 loss 0.14303 val_loss 0.14303 \n",
            "Epoch 9/10 loss -6.29345 val_loss -6.29345 \n",
            "Epoch 9/10 loss 16.45597 val_loss 16.45597 \n",
            "Epoch 9/10 loss 0.00032 val_loss 0.00032 \n",
            "Epoch 9/10 loss 14.90234 val_loss 14.90234 \n",
            "Epoch 9/10 loss 11.72108 val_loss 11.72108 \n",
            "Epoch 9/10 loss -10.23224 val_loss -10.23224 \n",
            "Epoch 9/10 loss -29.35292 val_loss -29.35292 \n",
            "Epoch 9/10 loss 0.00000 val_loss 0.00000 \n",
            "Epoch 9/10 loss 21.67242 val_loss 21.67242 \n",
            "Epoch 9/10 loss 13.78740 val_loss 13.78740 \n",
            "Epoch 9/10 loss 20.86780 val_loss 20.86780 \n",
            "Epoch 9/10 loss 19.20399 val_loss 19.20399 \n",
            "Epoch 9/10 loss 11.79790 val_loss 11.79790 \n",
            "Epoch 9/10 loss -6.03865 val_loss -6.03865 \n",
            "Epoch 9/10 loss 14.04530 val_loss 14.04530 \n",
            "Epoch 9/10 loss 10.26292 val_loss 10.26292 \n",
            "Epoch 9/10 loss 0.65009 val_loss 0.65009 \n",
            "Epoch 9/10 loss 0.13653 val_loss 0.13653 \n",
            "Epoch 9/10 loss 0.72138 val_loss 0.72138 \n",
            "Epoch 9/10 loss 0.82829 val_loss 0.82829 \n",
            "Epoch 9/10 loss -3.34858 val_loss -3.34858 \n",
            "Epoch 9/10 loss -1.11640 val_loss -1.11640 \n",
            "Epoch 9/10 loss 3.24806 val_loss 3.24806 \n",
            "Epoch 9/10 loss -1.83218 val_loss -1.83218 \n",
            "Epoch 9/10 loss -3.67699 val_loss -3.67699 \n",
            "Epoch 9/10 loss -7.77932 val_loss -7.77932 \n",
            "Epoch 9/10 loss 0.72896 val_loss 0.72896 \n",
            "Epoch 9/10 loss -5.34139 val_loss -5.34139 \n",
            "Epoch 9/10 loss 7.29308 val_loss 7.29308 \n",
            "Epoch 9/10 loss -0.23097 val_loss -0.23097 \n",
            "Epoch 9/10 loss -0.16250 val_loss -0.16250 \n",
            "Epoch 9/10 loss -2.29764 val_loss -2.29764 \n",
            "Epoch 9/10 loss -0.20187 val_loss -0.20187 \n",
            "Epoch 9/10 loss -0.13168 val_loss -0.13168 \n",
            "Epoch 9/10 loss -4.09492 val_loss -4.09492 \n",
            "Epoch 9/10 loss -0.18563 val_loss -0.18563 \n",
            "Epoch 9/10 loss -2.68904 val_loss -2.68904 \n",
            "Epoch 9/10 loss 2.38238 val_loss 2.38238 \n",
            "Epoch 9/10 loss -2.88999 val_loss -2.88999 \n",
            "Epoch 9/10 loss 1.20752 val_loss 1.20752 \n",
            "Epoch 9/10 loss 3.59699 val_loss 3.59699 \n",
            "Epoch 9/10 loss -8.39134 val_loss -8.39134 \n",
            "Epoch 9/10 loss 0.60797 val_loss 0.60797 \n",
            "Epoch 9/10 loss 0.08088 val_loss 0.08088 \n",
            "Epoch 9/10 loss 0.68781 val_loss 0.68781 \n",
            "Epoch 9/10 loss 9.19272 val_loss 9.19272 \n",
            "Epoch 9/10 loss -1.40486 val_loss -1.40486 \n",
            "Epoch 9/10 loss 5.71816 val_loss 5.71816 \n",
            "Epoch 9/10 loss -11.50947 val_loss -11.50947 \n",
            "Epoch 9/10 loss 1.19411 val_loss 1.19411 \n",
            "Epoch 9/10 loss 1.11669 val_loss 1.11669 \n",
            "Epoch 9/10 loss 0.21040 val_loss 0.21040 \n",
            "Epoch 9/10 loss -0.07244 val_loss -0.07244 \n",
            "Epoch 9/10 loss 4.90353 val_loss 4.90353 \n",
            "Epoch 9/10 loss 1.01991 val_loss 1.01991 \n",
            "Epoch 9/10 loss -7.79928 val_loss -7.79928 \n",
            "Epoch 9/10 loss -3.00281 val_loss -3.00281 \n",
            "Epoch 9/10 loss -1.67025 val_loss -1.67025 \n",
            "Epoch 9/10 loss 3.32468 val_loss 3.32468 \n",
            "Epoch 9/10 loss 3.16519 val_loss 3.16519 \n",
            "Epoch 9/10 loss -0.47070 val_loss -0.47070 \n",
            "Epoch 9/10 loss 0.29961 val_loss 0.29961 \n",
            "Epoch 9/10 loss 0.56165 val_loss 0.56165 \n",
            "Epoch 9/10 loss 2.36287 val_loss 2.36287 \n",
            "Epoch 9/10 loss -1.64434 val_loss -1.64434 \n",
            "Epoch 9/10 loss -2.55587 val_loss -2.55587 \n",
            "Epoch 9/10 loss -2.06967 val_loss -2.06967 \n",
            "Epoch 9/10 loss -6.26299 val_loss -6.26299 \n",
            "Epoch 9/10 loss -3.47322 val_loss -3.47322 \n",
            "Epoch 9/10 loss -7.38719 val_loss -7.38719 \n",
            "Epoch 9/10 loss -2.07564 val_loss -2.07564 \n",
            "Epoch 9/10 loss -0.81081 val_loss -0.81081 \n",
            "Epoch 9/10 loss 0.00459 val_loss 0.00459 \n",
            "Epoch 9/10 loss -1.06066 val_loss -1.06066 \n",
            "Epoch 9/10 loss 0.00275 val_loss 0.00275 \n",
            "Epoch 9/10 loss -4.95681 val_loss -4.95681 \n",
            "Epoch 9/10 loss -8.61089 val_loss -8.61089 \n",
            "Epoch 9/10 loss -1.31878 val_loss -1.31878 \n",
            "Epoch 9/10 loss 3.09119 val_loss 3.09119 \n",
            "Epoch 9/10 loss -11.87549 val_loss -11.87549 \n",
            "Epoch 9/10 loss 11.54930 val_loss 11.54930 \n",
            "Epoch 9/10 loss -2.38068 val_loss -2.38068 \n",
            "Epoch 9/10 loss 4.14669 val_loss 4.14669 \n",
            "Epoch 9/10 loss 7.49824 val_loss 7.49824 \n",
            "Epoch 9/10 loss 0.00056 val_loss 0.00056 \n",
            "Epoch 9/10 loss -7.75992 val_loss -7.75992 \n",
            "Epoch 9/10 loss 11.50926 val_loss 11.50926 \n",
            "Epoch 9/10 loss -6.89889 val_loss -6.89889 \n",
            "Epoch 9/10 loss -14.08241 val_loss -14.08241 \n",
            "Epoch 9/10 loss 3.25454 val_loss 3.25454 \n",
            "Epoch 9/10 loss 17.20773 val_loss 17.20773 \n",
            "Epoch 9/10 loss 4.12381 val_loss 4.12381 \n",
            "Epoch 9/10 loss -6.73487 val_loss -6.73487 \n",
            "Epoch 9/10 loss -5.02943 val_loss -5.02943 \n",
            "Epoch 9/10 loss -11.77539 val_loss -11.77539 \n",
            "Epoch 9/10 loss 1.17971 val_loss 1.17971 \n",
            "Epoch 9/10 loss 0.17178 val_loss 0.17178 \n",
            "Epoch 9/10 loss 5.79192 val_loss 5.79192 \n",
            "Epoch 9/10 loss -6.42942 val_loss -6.42942 \n",
            "Epoch 9/10 loss 1.44150 val_loss 1.44150 \n",
            "Epoch 9/10 loss 3.90220 val_loss 3.90220 \n",
            "Epoch 9/10 loss 1.99428 val_loss 1.99428 \n",
            "Epoch 9/10 loss 17.51706 val_loss 17.51706 \n",
            "Epoch 9/10 loss -10.29620 val_loss -10.29620 \n",
            "Epoch 9/10 loss 3.37262 val_loss 3.37262 \n",
            "Epoch 9/10 loss 13.74113 val_loss 13.74113 \n",
            "Epoch 9/10 loss 0.20222 val_loss 0.20222 \n",
            "Epoch 9/10 loss 5.65717 val_loss 5.65717 \n",
            "Epoch 9/10 loss -8.98150 val_loss -8.98150 \n",
            "Epoch 9/10 loss 8.28253 val_loss 8.28253 \n",
            "Epoch 9/10 loss -6.19846 val_loss -6.19846 \n",
            "Epoch 9/10 loss -6.29306 val_loss -6.29306 \n",
            "Epoch 9/10 loss 12.75165 val_loss 12.75165 \n",
            "Epoch 9/10 loss -1.39977 val_loss -1.39977 \n",
            "Epoch 9/10 loss -19.41879 val_loss -19.41879 \n",
            "Epoch 9/10 loss -7.67449 val_loss -7.67449 \n",
            "Epoch 9/10 loss 6.82073 val_loss 6.82073 \n",
            "Epoch 9/10 loss -10.72913 val_loss -10.72913 \n",
            "Epoch 9/10 loss -19.82559 val_loss -19.82559 \n",
            "Epoch 9/10 loss 4.15369 val_loss 4.15369 \n",
            "Epoch 9/10 loss -9.17549 val_loss -9.17549 \n",
            "Epoch 9/10 loss -0.08790 val_loss -0.08790 \n",
            "Epoch 9/10 loss -14.16813 val_loss -14.16813 \n",
            "Epoch 9/10 loss -16.29965 val_loss -16.29965 \n",
            "Epoch 9/10 loss 18.97807 val_loss 18.97807 \n",
            "Epoch 9/10 loss 11.76754 val_loss 11.76754 \n",
            "Epoch 9/10 loss -10.62484 val_loss -10.62484 \n",
            "Epoch 9/10 loss 9.04883 val_loss 9.04883 \n",
            "Epoch 9/10 loss 15.28463 val_loss 15.28463 \n",
            "Epoch 9/10 loss 8.42080 val_loss 8.42080 \n",
            "Epoch 9/10 loss -3.15055 val_loss -3.15055 \n",
            "Epoch 9/10 loss -7.35115 val_loss -7.35115 \n",
            "Epoch 9/10 loss 2.67844 val_loss 2.67844 \n",
            "Epoch 9/10 loss 2.81567 val_loss 2.81567 \n",
            "Epoch 9/10 loss 5.50660 val_loss 5.50660 \n",
            "Epoch 9/10 loss -4.71004 val_loss -4.71004 \n",
            "Epoch 10/10 loss -10.51841 val_loss -10.51841 \n",
            "Epoch 10/10 loss 12.91088 val_loss 12.91088 \n",
            "Epoch 10/10 loss -1.83062 val_loss -1.83062 \n",
            "Epoch 10/10 loss 2.90408 val_loss 2.90408 \n",
            "Epoch 10/10 loss -21.40847 val_loss -21.40847 \n",
            "Epoch 10/10 loss 6.13880 val_loss 6.13880 \n",
            "Epoch 10/10 loss -5.90747 val_loss -5.90747 \n",
            "Epoch 10/10 loss -15.34440 val_loss -15.34440 \n",
            "Epoch 10/10 loss 4.54935 val_loss 4.54935 \n",
            "Epoch 10/10 loss 2.19659 val_loss 2.19659 \n",
            "Epoch 10/10 loss 0.12705 val_loss 0.12705 \n",
            "Epoch 10/10 loss -6.70060 val_loss -6.70060 \n",
            "Epoch 10/10 loss 14.77916 val_loss 14.77916 \n",
            "Epoch 10/10 loss -22.20514 val_loss -22.20514 \n",
            "Epoch 10/10 loss 7.48383 val_loss 7.48383 \n",
            "Epoch 10/10 loss -7.71248 val_loss -7.71248 \n",
            "Epoch 10/10 loss 8.73480 val_loss 8.73480 \n",
            "Epoch 10/10 loss -30.81170 val_loss -30.81170 \n",
            "Epoch 10/10 loss 4.25240 val_loss 4.25240 \n",
            "Epoch 10/10 loss -31.74360 val_loss -31.74360 \n",
            "Epoch 10/10 loss 18.18268 val_loss 18.18268 \n",
            "Epoch 10/10 loss -8.31600 val_loss -8.31600 \n",
            "Epoch 10/10 loss 8.38187 val_loss 8.38187 \n",
            "Epoch 10/10 loss -0.55928 val_loss -0.55928 \n",
            "Epoch 10/10 loss -25.81927 val_loss -25.81927 \n",
            "Epoch 10/10 loss 4.35231 val_loss 4.35231 \n",
            "Epoch 10/10 loss -0.07474 val_loss -0.07474 \n",
            "Epoch 10/10 loss -7.04537 val_loss -7.04537 \n",
            "Epoch 10/10 loss -13.16327 val_loss -13.16327 \n",
            "Epoch 10/10 loss 10.99589 val_loss 10.99589 \n",
            "Epoch 10/10 loss 0.02429 val_loss 0.02429 \n",
            "Epoch 10/10 loss -18.80237 val_loss -18.80237 \n",
            "Epoch 10/10 loss 0.43721 val_loss 0.43721 \n",
            "Epoch 10/10 loss -9.66435 val_loss -9.66435 \n",
            "Epoch 10/10 loss 0.80037 val_loss 0.80037 \n",
            "Epoch 10/10 loss -29.79216 val_loss -29.79216 \n",
            "Epoch 10/10 loss 30.44419 val_loss 30.44419 \n",
            "Epoch 10/10 loss 9.21390 val_loss 9.21390 \n",
            "Epoch 10/10 loss -0.58393 val_loss -0.58393 \n",
            "Epoch 10/10 loss -16.59107 val_loss -16.59107 \n",
            "Epoch 10/10 loss 0.46045 val_loss 0.46045 \n",
            "Epoch 10/10 loss 35.87555 val_loss 35.87555 \n",
            "Epoch 10/10 loss 0.59461 val_loss 0.59461 \n",
            "Epoch 10/10 loss 1.37160 val_loss 1.37160 \n",
            "Epoch 10/10 loss -17.43502 val_loss -17.43502 \n",
            "Epoch 10/10 loss 17.24670 val_loss 17.24670 \n",
            "Epoch 10/10 loss -17.86705 val_loss -17.86705 \n",
            "Epoch 10/10 loss -1.62604 val_loss -1.62604 \n",
            "Epoch 10/10 loss 4.23943 val_loss 4.23943 \n",
            "Epoch 10/10 loss -1.58748 val_loss -1.58748 \n",
            "Epoch 10/10 loss 0.99610 val_loss 0.99610 \n",
            "Epoch 10/10 loss -8.59648 val_loss -8.59648 \n",
            "Epoch 10/10 loss -2.93616 val_loss -2.93616 \n",
            "Epoch 10/10 loss -10.54961 val_loss -10.54961 \n",
            "Epoch 10/10 loss -0.87485 val_loss -0.87485 \n",
            "Epoch 10/10 loss -15.11193 val_loss -15.11193 \n",
            "Epoch 10/10 loss 0.05153 val_loss 0.05153 \n",
            "Epoch 10/10 loss -10.06414 val_loss -10.06414 \n",
            "Epoch 10/10 loss 1.19367 val_loss 1.19367 \n",
            "Epoch 10/10 loss -1.06856 val_loss -1.06856 \n",
            "Epoch 10/10 loss -21.22398 val_loss -21.22398 \n",
            "Epoch 10/10 loss 21.02268 val_loss 21.02268 \n",
            "Epoch 10/10 loss 10.34488 val_loss 10.34488 \n",
            "Epoch 10/10 loss 0.92479 val_loss 0.92479 \n",
            "Epoch 10/10 loss 9.60768 val_loss 9.60768 \n",
            "Epoch 10/10 loss -1.25600 val_loss -1.25600 \n",
            "Epoch 10/10 loss -20.35277 val_loss -20.35277 \n",
            "Epoch 10/10 loss 13.12206 val_loss 13.12206 \n",
            "Epoch 10/10 loss 0.13377 val_loss 0.13377 \n",
            "Epoch 10/10 loss -10.87796 val_loss -10.87796 \n",
            "Epoch 10/10 loss -0.69211 val_loss -0.69211 \n",
            "Epoch 10/10 loss 11.40967 val_loss 11.40967 \n",
            "Epoch 10/10 loss 18.40550 val_loss 18.40550 \n",
            "Epoch 10/10 loss -39.40500 val_loss -39.40500 \n",
            "Epoch 10/10 loss 0.02241 val_loss 0.02241 \n",
            "Epoch 10/10 loss 9.15021 val_loss 9.15021 \n",
            "Epoch 10/10 loss -21.96436 val_loss -21.96436 \n",
            "Epoch 10/10 loss -22.78385 val_loss -22.78385 \n",
            "Epoch 10/10 loss 21.05243 val_loss 21.05243 \n",
            "Epoch 10/10 loss 5.25832 val_loss 5.25832 \n",
            "Epoch 10/10 loss -21.20591 val_loss -21.20591 \n",
            "Epoch 10/10 loss 16.99820 val_loss 16.99820 \n",
            "Epoch 10/10 loss -2.95828 val_loss -2.95828 \n",
            "Epoch 10/10 loss -11.08175 val_loss -11.08175 \n",
            "Epoch 10/10 loss -2.27671 val_loss -2.27671 \n",
            "Epoch 10/10 loss -18.34907 val_loss -18.34907 \n",
            "Epoch 10/10 loss 13.11446 val_loss 13.11446 \n",
            "Epoch 10/10 loss 0.00567 val_loss 0.00567 \n",
            "Epoch 10/10 loss 8.35657 val_loss 8.35657 \n",
            "Epoch 10/10 loss -7.27848 val_loss -7.27848 \n",
            "Epoch 10/10 loss 1.31882 val_loss 1.31882 \n",
            "Epoch 10/10 loss 2.26071 val_loss 2.26071 \n",
            "Epoch 10/10 loss 0.27330 val_loss 0.27330 \n",
            "Epoch 10/10 loss -0.03078 val_loss -0.03078 \n",
            "Epoch 10/10 loss 4.40874 val_loss 4.40874 \n",
            "Epoch 10/10 loss 9.22587 val_loss 9.22587 \n",
            "Epoch 10/10 loss 0.00007 val_loss 0.00007 \n",
            "Epoch 10/10 loss 5.49012 val_loss 5.49012 \n",
            "Epoch 10/10 loss 16.25660 val_loss 16.25660 \n",
            "Epoch 10/10 loss -8.31870 val_loss -8.31870 \n",
            "Epoch 10/10 loss 6.96283 val_loss 6.96283 \n",
            "Epoch 10/10 loss 14.11764 val_loss 14.11764 \n",
            "Epoch 10/10 loss 1.26180 val_loss 1.26180 \n",
            "Epoch 10/10 loss -0.10976 val_loss -0.10976 \n",
            "Epoch 10/10 loss 0.33840 val_loss 0.33840 \n",
            "Epoch 10/10 loss 0.44191 val_loss 0.44191 \n",
            "Epoch 10/10 loss -0.31486 val_loss -0.31486 \n",
            "Epoch 10/10 loss -0.20528 val_loss -0.20528 \n",
            "Epoch 10/10 loss -2.84813 val_loss -2.84813 \n",
            "Epoch 10/10 loss -2.42402 val_loss -2.42402 \n",
            "Epoch 10/10 loss -0.05475 val_loss -0.05475 \n",
            "Epoch 10/10 loss -6.47060 val_loss -6.47060 \n",
            "Epoch 10/10 loss -7.64660 val_loss -7.64660 \n",
            "Epoch 10/10 loss -2.06329 val_loss -2.06329 \n",
            "Epoch 10/10 loss -5.49863 val_loss -5.49863 \n",
            "Epoch 10/10 loss 9.23472 val_loss 9.23472 \n",
            "Epoch 10/10 loss 7.34979 val_loss 7.34979 \n",
            "Epoch 10/10 loss -5.84598 val_loss -5.84598 \n",
            "Epoch 10/10 loss -14.81560 val_loss -14.81560 \n",
            "Epoch 10/10 loss 2.11207 val_loss 2.11207 \n",
            "Epoch 10/10 loss -7.83854 val_loss -7.83854 \n",
            "Epoch 10/10 loss -7.91366 val_loss -7.91366 \n",
            "Epoch 10/10 loss -4.73246 val_loss -4.73246 \n",
            "Epoch 10/10 loss 0.70633 val_loss 0.70633 \n",
            "Epoch 10/10 loss -11.41114 val_loss -11.41114 \n",
            "Epoch 10/10 loss -9.96581 val_loss -9.96581 \n",
            "Epoch 10/10 loss 1.21884 val_loss 1.21884 \n",
            "Epoch 10/10 loss -13.13905 val_loss -13.13905 \n",
            "Epoch 10/10 loss -12.24749 val_loss -12.24749 \n",
            "Epoch 10/10 loss 14.79661 val_loss 14.79661 \n",
            "Epoch 10/10 loss 6.48837 val_loss 6.48837 \n",
            "Epoch 10/10 loss 11.03660 val_loss 11.03660 \n",
            "Epoch 10/10 loss 8.29234 val_loss 8.29234 \n",
            "Epoch 10/10 loss -7.06288 val_loss -7.06288 \n",
            "Epoch 10/10 loss 12.96562 val_loss 12.96562 \n",
            "Epoch 10/10 loss -11.83415 val_loss -11.83415 \n",
            "Epoch 10/10 loss 6.19812 val_loss 6.19812 \n",
            "Epoch 10/10 loss 0.00000 val_loss 0.00000 \n",
            "Epoch 10/10 loss 10.95533 val_loss 10.95533 \n",
            "Epoch 10/10 loss 0.05610 val_loss 0.05610 \n",
            "Epoch 10/10 loss 4.20576 val_loss 4.20576 \n",
            "Epoch 10/10 loss -0.10532 val_loss -0.10532 \n",
            "Epoch 10/10 loss 0.36521 val_loss 0.36521 \n",
            "Epoch 10/10 loss -6.83281 val_loss -6.83281 \n",
            "Epoch 10/10 loss 1.05971 val_loss 1.05971 \n",
            "Epoch 10/10 loss -10.90448 val_loss -10.90448 \n",
            "Epoch 10/10 loss 17.76834 val_loss 17.76834 \n",
            "Epoch 10/10 loss -0.63418 val_loss -0.63418 \n",
            "Epoch 10/10 loss -7.69011 val_loss -7.69011 \n",
            "Epoch 10/10 loss -8.23642 val_loss -8.23642 \n",
            "tensor([[ 0.3489],\n",
            "        [-8.3290]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPKvUCYsxCaz"
      },
      "source": [
        "def predict(model, X):\n",
        "    model.eval() \n",
        "    with torch.no_grad():\n",
        "        X = torch.tensor(X).to(device)\n",
        "        pred = model(X)\n",
        "        return pred"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjT3KaN5xFsj",
        "outputId": "c1519954-f0f5-4134-dad7-1fcda48eb543"
      },
      "source": [
        "sentences = [\"en robótica con fineso\", \"The paper is well\", \"this film is good\", \"a waste of time\"]\n",
        "tokenized = [[tok.text for tok in spacy_en.tokenizer(sentence)] for sentence in sentences]\n",
        "indexed = [[Texto.vocab.stoi[_t] for _t in t] for t in tokenized]\n",
        "tensor = torch.tensor(indexed).permute(1,0)\n",
        "predictions = torch.argmax(predict(model, tensor), axis=1)\n",
        "predictions"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}